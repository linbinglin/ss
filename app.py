import streamlit as st
from openai import OpenAI
import re

# 1. é¡µé¢é…ç½®
st.set_page_config(page_title="ç”µå½±è§£è¯´AIåˆ†é•œ Pro", layout="wide", page_icon="ğŸ¬")

# --- åˆå§‹åŒ–æ•°æ®çŠ¶æ€ ---
if 'all_segments' not in st.session_state:
    st.session_state['all_segments'] = []
if 'batch_result' not in st.session_state:
    st.session_state['batch_result'] = ""

# 2. ä¾§è¾¹æ ï¼šé…ç½®å‚æ•°ä¸åç¼€
st.sidebar.title("âš™ï¸ å…¨å±€è®¾ç½®")
api_key = st.sidebar.text_input("1. API Key", type="password")
base_url = st.sidebar.text_input("2. æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")

st.sidebar.markdown("---")
st.sidebar.subheader("3. é£æ ¼åç¼€")
mj_suffix = st.sidebar.text_input("Midjourney åç¼€è¯", value="--ar 16:9 --v 6.1 --style raw")

st.sidebar.markdown("---")
st.sidebar.subheader("4. æ¨¡å‹è®¾ç½®")
model_options = ["gpt-4o", "claude-3-5-sonnet-20240620", "deepseek-chat", "è‡ªå®šä¹‰æ¨¡å‹ (æ‰‹åŠ¨è¾“å…¥)"]
selected_option = st.sidebar.selectbox("é€‰æ‹©å¤§è„‘", model_options)

if selected_option == "è‡ªå®šä¹‰æ¨¡å‹ (æ‰‹åŠ¨è¾“å…¥)":
    model_id = st.sidebar.text_input("è¯·è¾“å…¥å…·ä½“çš„ Model ID", placeholder="ä¾‹å¦‚ï¼šgpt-4-turbo")
else:
    model_id = selected_option

st.title("ğŸ¬ ç”µå½±è§£è¯´å…¨æµç¨‹åˆ†é•œå·¥å…·")
st.caption("ç¬¬ä¸€æ­¥ï¼šå¤ç”¨ v5.1 çº¯å‡€å¯¼æ¼”é€»è¾‘ | ç¬¬äºŒæ­¥ï¼šæ”¯æŒæ‰¹å¤„ç†ä¸è§†è§‰ä¸€è‡´æ€§é”šå®š")

# --- ç¬¬ä¸€é˜¶æ®µï¼šé€»è¾‘åˆ†é•œï¼ˆå®Œå…¨è¿˜åŸ v5.1 é€»è¾‘ï¼‰ ---
st.header("ç¬¬ä¸€æ­¥ï¼šé€»è¾‘åˆ†é•œï¼ˆæ„å»ºçº¯å‡€éª¨æ¶ï¼‰")

uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼ æ–‡æ¡ˆ (TXT)", type=['txt'])

if uploaded_file:
    raw_text = uploaded_file.getvalue().decode("utf-8", errors="ignore")
    # v5.1 æ ¸å¿ƒé¢„å¤„ç†ï¼šç‰©ç†æŠ¹é™¤æ¢è¡Œï¼Œåˆå¹¶ä¸ºçº¯æ–‡å­—æµ
    full_story = "".join(raw_text.split())

    if st.button("ğŸš€ ç”Ÿæˆé€»è¾‘åˆ†é•œè„šæœ¬", use_container_width=True):
        if not api_key or not model_id:
            st.error("è¯·å…ˆå¡«å…¥é…ç½®ä¿¡æ¯ï¼")
        else:
            client = OpenAI(api_key=api_key, base_url=base_url)
            
            # v5.1 æ ¸å¿ƒçº¯å‡€æç¤ºè¯
            STEP1_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæå…¶ä¸¥è°¨çš„ç”µå½±åˆ†é•œå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†æä¾›çš„ã€çº¯æ–‡å­—æµã€‘æ‹†è§£ä¸ºã€æ•°å­—ç¼–å·çš„åˆ†é•œè„šæœ¬ã€‘ã€‚

### æ ¸å¿ƒè§„åˆ™ï¼š
1. **ä¸¥æ ¼ç¼–å·**ï¼šæ¯ä¸€ä¸ªåˆ†é•œå¿…é¡»ä»¥â€œ1.â€ â€œ2.â€ â€œ3.â€ è¿™ç§æ•°å­—åºå·å¼€å¤´ï¼Œä¸å¾—é—æ¼ã€‚
2. **æ‹’ç»æ³¨é‡Š**ï¼šä¸¥ç¦åœ¨åˆ†é•œä¸­æ·»åŠ ä»»ä½•æ‹¬å·ã€åˆ†æã€é•œå¤´æ„å›¾æˆ–é¢å¤–æè¿°ã€‚åªéœ€è¾“å‡ºâ€œæ•°å­—. åŸæ–‡â€ã€‚
3. **è§†è§‰å•å…ƒåˆ‡åˆ†ï¼ˆä¸¥ç¦åˆå¹¶ï¼‰**ï¼š
   - ä¸€ä¸ªåˆ†é•œåªèƒ½åŒ…å«ä¸€ä¸ªè§†è§‰é‡ç‚¹æˆ–æ ¸å¿ƒåŠ¨ä½œã€‚
   - ä¸¥ç¦ä¸ºäº†çœäº‹å°†ä¸¤ä¸ªä¸åŒçš„åŠ¨ä½œï¼ˆå¦‚ï¼šä»–è·‘å›å®¶ã€ä»–åä¸‹å–æ°´ï¼‰åˆå¹¶åœ¨ä¸€ä¸ªåˆ†é•œé‡Œã€‚
4. **å­—æ•°ä¸æ—¶é•¿å¯¹é½**ï¼š
   - æ¯ä¸ªåˆ†é•œç›®æ ‡å­—æ•°ä¸º 25-35 å­—ã€‚
   - ç»å¯¹ä¸¥ç¦è¶…è¿‡ 40 å­—ã€‚
5. **åŸæ–‡é›¶æ”¹åŠ¨**ï¼šä¸å‡†æ”¹å­—ã€åˆ å­—ã€åŠ å­—ã€‚
"""
            with st.spinner("æ­£åœ¨é€å¥æ·±åº¦è§£æå¹¶ç²¾å‡†åˆ†é•œ..."):
                try:
                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[{"role": "system", "content": STEP1_PROMPT},
                                  {"role": "user", "content": f"è¯·å¯¹ä»¥ä¸‹æ–‡å­—æµè¿›è¡Œç­‰æƒé‡çš„ç²¾ç¡®åˆ†é•œï¼Œä»å¤´åˆ°å°¾ä¿æŒé«˜ç²¾åº¦æ‹†è§£ï¼Œå¿…é¡»å¸¦æ•°å­—ç¼–å·ï¼š\n\n{full_story}"}],
                        temperature=0.1
                    )
                    # å°†ç»“æœä¿å­˜å¹¶è§£æ
                    st.session_state['all_segments'] = [l.strip() for l in response.choices[0].message.content.split('\n') if re.match(r'^\d+', l.strip())]
                except Exception as e:
                    st.error(f"å¤„ç†å¤±è´¥: {str(e)}")

# å±•ç¤ºå¹¶æ£€æŸ¥ç¬¬ä¸€æ­¥ç»“æœ
if st.session_state['all_segments']:
    st.subheader(f"ğŸ“‹ åˆ†é•œéª¨æ¶é¢„è§ˆ (å…± {len(st.session_state['all_segments'])} ç»„)")
    
    # å­—æ•°ç›‘æµ‹æ˜¾ç¤º
    for line in st.session_state['all_segments'][:10]: # é¢„è§ˆå‰10æ¡
        text_only = re.sub(r'^\d+[\.ã€\s]+', '', line)
        length = len(text_only)
        if length > 40: st.error(f"âŒ {line} (å­—æ•°è¶…æ ‡: {length})")
        else: st.success(f"âœ… {line} (å­—æ•°: {length})")
    
    st.info("å¦‚éœ€å¾®è°ƒï¼Œè¯·åœ¨ä¸‹æ–¹æ–‡æœ¬æ¡†ä¿®æ”¹åç»§ç»­ã€‚")
    edited_text = st.text_area("åˆ†é•œæ–‡æ¡ˆå†…å®¹", "\n".join(st.session_state['all_segments']), height=250)
    st.session_state['all_segments'] = [l.strip() for l in edited_text.split('\n') if re.match(r'^\d+', l.strip())]

    st.markdown("---")

    # --- ç¬¬äºŒé˜¶æ®µï¼šåˆ†é•œæè¿°ï¼ˆæŒ‰æ‰¹æ¬¡å¾®è°ƒç‰ˆï¼‰ ---
    st.header("ç¬¬äºŒæ­¥ï¼šè§†è§‰åŒ–æ‰©å……ï¼ˆæ‰¹å¤„ç†æ¨¡å¼ï¼‰")
    
    col1, col2 = st.columns([1, 1])
    with col1:
        char_desc = st.text_area("ğŸ‘¤ è§’è‰²å½¢è±¡è®¾å®š (è°ƒç”¨é€»è¾‘ï¼šåˆ†é•œå‡ºç°å³å¼•ç”¨)", 
                                 placeholder="ä¾‹ï¼šæ—å‡¡ï¼š(25å²ï¼Œç„è‰²åˆºç»£é•¿è¢ï¼Œç›®å…‰å¦‚ç”µï¼Œé»‘è‰²é©¬å°¾)ã€‚\nè‹æ™´ï¼š(18å²ï¼Œç´«è‰²çº±è£™ï¼Œè´è¶ç°ª)ã€‚",
                                 height=200)
    with col2:
        st.info("ğŸ’¡ æ‰¹å¤„ç†æ¨¡å¼ï¼šå»ºè®®æ¯æ¬¡ç”Ÿæˆ 20 ç»„ï¼Œä»¥ä¿è¯è§†è§‰æè¿°çš„ç»†è‡´åº¦ã€‚")
        total_len = len(st.session_state['all_segments'])
        batch_size = 20
        batch_options = [f"ç¬¬ {i+1} - {min(i+batch_size, total_len)} ç»„" for i in range(0, total_len, batch_size)]
        selected_batch = st.selectbox("é€‰æ‹©è¦ç”Ÿæˆçš„æ‰¹æ¬¡", batch_options)
        
        # è§£æé€‰ä¸­ç´¢å¼•
        match = re.findall(r'\d+', selected_batch)
        start_idx = int(match[0]) - 1
        end_idx = int(match[1])

    if st.button(f"ğŸ¨ ä¸º {selected_batch} ç”Ÿæˆæè¿°è¯", use_container_width=True):
        if not char_desc:
            st.error("è¯·å…ˆå¡«å†™è§’è‰²å½¢è±¡è®¾å®šï¼")
        else:
            client = OpenAI(api_key=api_key, base_url=base_url)
            current_batch_data = "\n".join(st.session_state['all_segments'][start_idx:end_idx])
            
            # ç¬¬äºŒæ­¥æç¤ºè¯ï¼šå¢åŠ æ‹¬å·è°ƒç”¨ä¸åœºæ™¯å¼ºåˆ¶æè¿°
            STEP2_PROMPT = f"""ä½ æ˜¯ä¸€ä¸ªè§†è§‰å¯¼æ¼”ã€‚ä¸ºåˆ†é•œè„šæœ¬é…ä¸Šè§†è§‰æŒ‡ä»¤ã€‚

### æ ¸å¿ƒè§„åˆ™ï¼š
1. **è§†è§‰é”šå®š**ï¼šæ–‡æ¡ˆä¸­å‡ºç°è§’è‰²æ—¶ï¼Œå¿…é¡»å®Œæ•´è°ƒç”¨ä»¥ä¸‹å½¢è±¡ï¼Œå¹¶ç”¨æ‹¬å·åŒ…è£¹ã€‚
è§’è‰²è®¾å®šï¼š{char_desc}
2. **åœºæ™¯å¼ºåˆ¶æè¿°**ï¼šæ¯ä¸€ä¸ªåˆ†é•œå¿…é¡»æ˜ç¡®æè¿°åœºæ™¯ç¯å¢ƒå’Œå…‰å½±æ°›å›´ï¼Œé˜²æ­¢AIéšæœºç”Ÿæˆã€‚
3. **æ ¼å¼åŒ–è¾“å‡º**ï¼š
   - ç”»é¢æè¿°ï¼ˆé™æ€ï¼‰ï¼šæè¿°åœºæ™¯ã€å…‰å½±ã€(äººç‰©å½¢è±¡æè¿°)ã€è§†è§’ã€‚æœ«å°¾å›ºå®šåŠ ä¸Šåç¼€è¯ï¼š{mj_suffix}
   - è§†é¢‘ç”Ÿæˆï¼ˆåŠ¨æ€ï¼‰ï¼šæè¿°äººç‰©åŠ¨ä½œè¡Œä¸ºã€ç¥æ€ã€é•œå¤´è¿åŠ¨ã€‚
4. **åŸæ–‡å¤è¯»**ï¼šä¸¥ç¦æ”¹åŠ¨åˆ†é•œä¸­çš„æ–‡æ¡ˆåŸæ–‡ã€‚

### è¾“å‡ºæ ¼å¼ï¼š
---
[åºå·]. [æ–‡æ¡ˆåŸæ–‡]
ç”»é¢æè¿°ï¼š[åœºæ™¯ç»†èŠ‚], [å…‰å½±], (äººç‰©å…·ä½“å½¢è±¡æå†™), [æ„å›¾è§†è§’] {mj_suffix}
è§†é¢‘ç”Ÿæˆï¼š[åŠ¨ä½œè¿‡ç¨‹], [ç¥æ€æ¼”å˜], [é•œå¤´è¿åŠ¨]
---"""

            with st.spinner(f"æ­£åœ¨åˆ†æ {selected_batch} ..."):
                try:
                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[{"role": "system", "content": STEP2_PROMPT},
                                  {"role": "user", "content": current_batch_data}],
                        temperature=0.4
                    )
                    st.session_state['batch_result'] = response.choices[0].message.content
                    st.success("æ‰¹æ¬¡ç”ŸæˆæˆåŠŸï¼")
                except Exception as e:
                    st.error(f"å¤„ç†å¤±è´¥: {str(e)}")

    if st.session_state['batch_result']:
        st.subheader(f"ğŸ¥ {selected_batch} è§†è§‰æ–¹æ¡ˆ")
        st.text_area("ç»“æœé¢„è§ˆ", st.session_state['batch_result'], height=400)
        st.download_button(f"ğŸ“¥ ä¸‹è½½{selected_batch}", st.session_state['batch_result'], file_name=f"åˆ†é•œæè¿°_{selected_batch}.txt")

st.markdown("---")
st.caption("åˆ†é•œåŠ©æ‰‹ v6.1 | å·²å¤åŸ v5.1 ç¬¬ä¸€æ­¥é€»è¾‘ | ä¼˜åŒ–ç¬¬äºŒæ­¥äººç‰©ä¸€è‡´æ€§ä¸ç”»é£åç¼€")
