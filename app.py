import streamlit as st
from openai import OpenAI
import re

# 1. é¡µé¢é…ç½®
st.set_page_config(page_title="AI ç”µå½±å¯¼æ¼” Pro v6.2", layout="wide", page_icon="ğŸ¬")

# --- æ•°æ®æŒä¹…åŒ– ---
if 'all_segments' not in st.session_state:
    st.session_state['all_segments'] = []
if 'batch_result' not in st.session_state:
    st.session_state['batch_result'] = ""

# 2. ä¾§è¾¹æ 
st.sidebar.title("âš™ï¸ é…ç½®ä¸­å¿ƒ")
api_key = st.sidebar.text_input("1. API Key", type="password")
base_url = st.sidebar.text_input("2. æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")

st.sidebar.markdown("---")
st.sidebar.subheader("3. é£æ ¼åç¼€è¯")
mj_suffix = st.sidebar.text_input("MJ åç¼€ (å›ºå®šç”»é£)", value="--ar 16:9 --v 6.1 --style raw")

st.sidebar.markdown("---")
model_options = ["gpt-4o", "claude-3-5-sonnet-20240620", "deepseek-chat", "è‡ªå®šä¹‰æ¨¡å‹"]
selected_option = st.sidebar.selectbox("4. é€‰æ‹©å¤§è„‘", model_options)
if selected_option == "è‡ªå®šä¹‰æ¨¡å‹":
    model_id = st.sidebar.text_input("è¯·è¾“å…¥å…·ä½“çš„ Model ID")
else:
    model_id = selected_option

st.title("ğŸ¬ ç”µå½±è§£è¯´å…¨æµç¨‹åˆ†é•œå·¥å…·")
st.caption("ç²¾å‡†è¿˜åŸ v5.1 å™äº‹åˆ†é•œé€»è¾‘ | è§†è§‰é”šå®šæ‰¹å¤„ç†")

# --- ç¬¬ä¸€é˜¶æ®µï¼šè¿˜åŸ v5.1 çº¯å‡€åˆ†é•œé€»è¾‘ ---
st.header("ç¬¬ä¸€æ­¥ï¼šå™äº‹é€»è¾‘åˆ†é•œï¼ˆè¿˜åŸ v5.1 æ ¸å¿ƒèŠ‚å¥ï¼‰")

uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼ æ–‡æ¡ˆ (TXT)", type=['txt'])

if uploaded_file:
    raw_text = uploaded_file.getvalue().decode("utf-8", errors="ignore")
    # v5.1 æ ¸å¿ƒé¢„å¤„ç†ï¼šç‰©ç†æŠ¹é™¤æ¢è¡Œï¼Œåˆ‡æ–­ä¸€åˆ‡åŸæ ¼å¼å‚è€ƒ
    clean_stream = "".join(raw_text.split())

    if st.button("ğŸš€ ç”Ÿæˆå™äº‹æ„Ÿåˆ†é•œè„šæœ¬", use_container_width=True):
        if not api_key:
            st.error("è¯·å…ˆé…ç½® API Key")
        else:
            client = OpenAI(api_key=api_key, base_url=base_url)
            
            # ç²¾å‡†è¿˜åŸ v5.1 æç¤ºè¯é€»è¾‘ï¼šå¼ºè°ƒâ€œè§†è§‰è¿è´¯æ€§â€ä¸‹çš„åˆ‡åˆ†
            STEP1_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæå…¶ä¸¥è°¨çš„ç”µå½±åˆ†é•œå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†æä¾›çš„ã€çº¯æ–‡å­—æµã€‘æ‹†è§£ä¸ºã€å™äº‹æ„Ÿæå¼ºçš„åˆ†é•œè„šæœ¬ã€‘ã€‚

### æ ¸å¿ƒåˆ†é•œé€»è¾‘ï¼ˆè¿˜åŸ v5.1 ç²¾é«“ï¼‰ï¼š
1. **ä¸¥æ ¼ç¼–å·**ï¼šå¿…é¡»ä»¥â€œ1.â€ â€œ2.â€è¿™ç§æ•°å­—åºå·å¼€å¤´ã€‚
2. **æ‹’ç»æ³¨é‡Š**ï¼šä¸¥ç¦è¾“å‡ºä»»ä½•åˆ†æã€æ‹¬å·ã€æ³¨é‡Šï¼Œåªéœ€è¾“å‡ºâ€œæ•°å­—. åŸæ–‡â€ã€‚
3. **åˆ†é•œåˆ‡åˆ†ç‚¹ï¼ˆå¯»æ‰¾è§†è§‰èŠ‚æ‹ï¼‰**ï¼š
   - å¿…é¡»åœ¨äººç‰©åŠ¨ä½œå¤§è½¬æŠ˜ã€åœºæ™¯åˆ‡æ¢ã€æˆ–è¯´è¯äººå˜åŒ–æ—¶åˆ‡åˆ†ã€‚
   - **ä¸è¦ç¢ç‰‡åŒ–**ï¼šå¦‚æœè¿ç»­çš„å¾®å°åŠ¨ä½œï¼ˆå¦‚ï¼šä»–è¿›é—¨ã€è½¬å¤´ã€çœ‹åˆ°æ¡Œå­ï¼‰é€»è¾‘è¿è´¯ä¸”æ€»å­—æ•°åœ¨ 25-35 å­—å†…ï¼Œè¯·ã€åˆå¹¶ã€‘åœ¨ä¸€ä¸ªåˆ†é•œé‡Œï¼Œä¸è¦å¼ºè¡Œæ‹†æ•£ã€‚
4. **ç‰©ç†ç¡¬æŒ‡æ ‡**ï¼š
   - æ¯ä¸ªåˆ†é•œç›®æ ‡å­—æ•°ä¸º 25-35 å­—ã€‚
   - ä¸¥ç¦è¶…è¿‡ 40 å­—ï¼ˆå¯¹åº”5ç§’é…éŸ³æé™ï¼‰ã€‚
5. **åŸæ–‡é›¶æ”¹åŠ¨**ï¼šç»å¯¹ä¸å‡†å¤šã€å°‘ã€æ”¹ä»»ä½•ä¸€ä¸ªå­—ã€‚
"""
            with st.spinner("æ­£åœ¨è¿˜åŸ v5.1 å™äº‹èŠ‚å¥è¿›è¡Œåˆ†é•œ..."):
                try:
                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[{"role": "system", "content": STEP1_PROMPT},
                                  {"role": "user", "content": f"è¯·å¯¹ä»¥ä¸‹æ–‡å­—æµè¿›è¡Œå™äº‹é€»è¾‘åˆ‡åˆ†ï¼Œå¿…é¡»å¸¦æ•°å­—ç¼–å·ï¼š\n\n{clean_stream}"}],
                        temperature=0.1
                    )
                    st.session_state['all_segments'] = [l.strip() for l in response.choices[0].message.content.split('\n') if re.match(r'^\d+', l.strip())]
                except Exception as e:
                    st.error(f"å¤„ç†å¤±è´¥: {str(e)}")

# ç»“æœé¢„è§ˆä¸å®æ—¶åé¦ˆ
if st.session_state['all_segments']:
    st.subheader(f"ğŸ“‹ åˆ†é•œéª¨æ¶é¢„è§ˆ (å…± {len(st.session_state['all_segments'])} ç»„)")
    
    # æ¸²æŸ“å‰ 10 æ¡æ£€æµ‹å­—æ•°
    for line in st.session_state['all_segments'][:10]:
        text_only = re.sub(r'^\d+[\.ã€\s]+', '', line)
        length = len(text_only)
        if length > 40: st.error(f"âŒ {line} (å­—æ•°è¶…æ ‡: {length})")
        else: st.success(f"âœ… {line} (å­—æ•°: {length})")
    
    st.info("å¦‚åˆ†é•œåˆ‡åˆ†ç‚¹ä¸ç¬¦åˆé¢„æœŸï¼Œè¯·åœ¨ä¸‹æ–¹æ–‡æœ¬æ¡†æ‰‹åŠ¨å¾®è°ƒã€‚")
    edited_text = st.text_area("åˆ†é•œæ–‡æ¡ˆå†…å®¹ç¼–è¾‘åŒº", "\n".join(st.session_state['all_segments']), height=250)
    st.session_state['all_segments'] = [l.strip() for l in edited_text.split('\n') if re.match(r'^\d+', l.strip())]

    st.markdown("---")

    # --- ç¬¬äºŒé˜¶æ®µï¼šæ‰¹å¤„ç†è§†è§‰æè¿° ---
    st.header("ç¬¬äºŒæ­¥ï¼šè§†è§‰åŒ–æè¿°æ‰©å……ï¼ˆåˆ†æ‰¹å¤„ç†ï¼‰")
    
    col_l, col_r = st.columns([1, 1])
    with col_l:
        char_desc = st.text_area("ğŸ‘¤ è§’è‰²å½¢è±¡è®¾å®š", 
                                 placeholder="ä¾‹ï¼šæ—å‡¡ï¼š(25å²ï¼Œç„è‰²é•¿è¢ï¼Œç›®å…‰å¦‚ç”µ)ã€‚\nè‹æ™´ï¼š(18å²ï¼Œç´«è‰²çº±è£™ï¼Œè´è¶ç°ª)ã€‚",
                                 height=200)
    with col_r:
        st.info("ğŸ’¡ æ‰¹å¤„ç†æ¨¡å¼ï¼šä¸ºäº†ç”Ÿæˆè´¨é‡ï¼Œå»ºè®®æ¯ 20 ç»„ä¸ºä¸€ä¸ªæ‰¹æ¬¡ç”Ÿæˆã€‚")
        total = len(st.session_state['all_segments'])
        batch_size = 20
        batch_options = [f"ç¬¬ {i+1} - {min(i+batch_size, total)} ç»„" for i in range(0, total, batch_size)]
        selected_batch = st.selectbox("é€‰æ‹©å½“å‰å¤„ç†æ‰¹æ¬¡", batch_options)
        
        # ç´¢å¼•è®¡ç®—
        indices = re.findall(r'\d+', selected_batch)
        start, end = int(indices[0]) - 1, int(indices[1])

    if st.button(f"ğŸ¨ ä¸º {selected_batch} ç”Ÿæˆè§†è§‰ç»†èŠ‚", use_container_width=True):
        if not char_info if 'char_info' in locals() else char_desc:
            st.error("è¯·å¡«å†™è§’è‰²è®¾å®šï¼")
        else:
            client = OpenAI(api_key=api_key, base_url=base_url)
            batch_data = "\n".join(st.session_state['all_segments'][start:end])
            
            STEP2_PROMPT = f"""ä½ æ˜¯ä¸€ä¸ªè§†è§‰å¯¼æ¼”ã€‚ä¸ºåˆ†é•œé…ä¸Šè§†è§‰æŒ‡ä»¤ã€‚

### æ ¸å¿ƒæ‰§è¡Œé€»è¾‘ï¼š
1. **è§†è§‰é”šå®š**ï¼šæ–‡æ¡ˆä¸­å‡ºç°è§’è‰²åï¼Œå¿…é¡»å®Œæ•´è°ƒç”¨ä»¥ä¸‹å½¢è±¡ï¼Œå¹¶ç”¨æ‹¬å·åŒ…è£¹ã€‚
è§’è‰²è®¾å®šï¼š{char_desc}
2. **åœºæ™¯å¼ºåˆ¶**ï¼šæ¯ä¸ªåˆ†é•œå¿…é¡»æè¿°å…·ä½“åœºæ™¯åœ°ç‚¹å’Œå…‰å½±æ°›å›´ï¼Œä¸¥ç¦è·³æˆã€‚
3. **æ ¼å¼åŒ–è¾“å‡º**ï¼š
   - ç”»é¢æè¿°ï¼š[åœºæ™¯æè¿°], [å…‰å½±], (äººç‰©å…·ä½“å½¢è±¡), [è§†è§’æ„å›¾] {mj_suffix}
   - è§†é¢‘ç”Ÿæˆï¼š[åŠ¨ä½œè¡Œä¸º], [ç¥æ€æ¼”å˜], [é•œå¤´æ§åˆ¶]ã€‚ç¡®ä¿5ç§’å†…å®Œæˆã€‚
4. **åŸæ–‡å¤è¯»**ï¼šä¸¥ç¦æ”¹åŠ¨è„šæœ¬åŸæ–‡ã€‚
"""
            with st.spinner(f"æ­£åœ¨åˆ†æ {selected_batch} çš„è§†è§‰ç»†èŠ‚..."):
                try:
                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[{"role": "system", "content": STEP2_PROMPT},
                                  {"role": "user", "content": batch_data}],
                        temperature=0.4
                    )
                    st.session_state['batch_result'] = response.choices[0].message.content
                except Exception as e:
                    st.error(f"å¤„ç†å¤±è´¥: {str(e)}")

    if st.session_state['batch_result']:
        st.subheader(f"ğŸ¥ {selected_batch} åˆ¶ä½œå…¨æ¡ˆ")
        st.text_area("ç»“æœé¢„è§ˆ", st.session_state['batch_result'], height=400)
        st.download_button(f"ğŸ“¥ ä¸‹è½½{selected_batch}", st.session_state['batch_result'], file_name=f"åˆ†é•œæè¿°_{selected_batch}.txt")

st.markdown("---")
st.caption("v6.2 è¿˜åŸä¼˜åŒ–ç‰ˆ | æ ¸å¿ƒï¼šå™äº‹æ„Ÿé‡å› v5.1 é€»è¾‘")
