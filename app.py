import streamlit as st
from openai import OpenAI

# 1. é¡µé¢é…ç½®
st.set_page_config(page_title="ç”µå½±è§£è¯´AIå¯¼æ¼” v4.0", layout="wide", page_icon="ğŸ¬")

if 'step1_result' not in st.session_state:
    st.session_state['step1_result'] = ""

# 2. ä¾§è¾¹æ 
st.sidebar.title("âš™ï¸ ç³»ç»Ÿé…ç½®")
api_key = st.sidebar.text_input("API Key", type="password")
base_url = st.sidebar.text_input("æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")
model_options = ["gpt-4o", "claude-3-5-sonnet-20240620", "deepseek-chat", "è‡ªå®šä¹‰æ¨¡å‹"]
selected_option = st.sidebar.selectbox("é€‰æ‹©æ¨¡å‹", model_options)
if selected_option == "è‡ªå®šä¹‰æ¨¡å‹":
    model_id = st.sidebar.text_input("Model ID")
else:
    model_id = selected_option

st.title("ğŸ¬ ç”µå½±è§£è¯´å…¨æµç¨‹åˆ†é•œå·¥å…· (ç²¾å‡†æ§æ—¶ç‰ˆ)")
st.markdown("---")

# --- ç¬¬ä¸€é˜¶æ®µï¼šç²¾å‡†æ§æ—¶åˆ†é•œ ---
st.header("ç¬¬ä¸€æ­¥ï¼šç²¾å‡†æ§æ—¶åˆ†é•œï¼ˆ5ç§’æ³•åˆ™ï¼‰")
st.info("ğŸ’¡ **åˆ†é•œé‡‘å¾‹**ï¼šæ¯ä¸ªåˆ†é•œç›®æ ‡å­—æ•°ä¸º **25-35å­—**ã€‚ä¸¥ç¦ä¸€ä¸ªåˆ†é•œå‡ºç°å¤šä¸ªå¤æ‚åŠ¨ä½œï¼Œç¡®ä¿ 5 ç§’è§†é¢‘èƒ½ä»å®¹å±•ç°ç”»é¢ã€‚")

uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼ æ–‡æ¡ˆ (TXT)", type=['txt'])

if uploaded_file:
    raw_text = uploaded_file.getvalue().decode("utf-8", errors="ignore")
    clean_stream = "".join(raw_text.split()) # æŠ¹é™¤æ‰€æœ‰æ ¼å¼

    if st.button("ğŸš€ æ‰§è¡Œç²¾å‡†èŠ‚å¥åˆ†é•œ", use_container_width=True):
        client = OpenAI(api_key=api_key, base_url=base_url)
        
        # æ ¸å¿ƒæç¤ºè¯ï¼šå¼•å…¥æ•°å­¦çº§çš„é™åˆ¶
        STEP1_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæå…¶ä¸¥è°¨çš„ç”µå½±è§£è¯´åˆ†é•œå¯¼æ¼”ã€‚
ä½ çš„ä»»åŠ¡æ˜¯å°†æ–‡å­—æµæ‹†åˆ†ä¸ºã€5ç§’å†…å¯å®Œæˆã€‘çš„è§†è§‰åˆ†é•œã€‚

### å¿…é¡»ä¸¥æ ¼æ‰§è¡Œçš„æ•°å­¦çº§å‡†åˆ™ï¼š
1. **å­—æ•°ç¡¬æŒ‡æ ‡ï¼ˆé»„é‡‘åŒºé—´ï¼‰**ï¼š
   - æ¯ä¸ªåˆ†é•œçš„æ–‡å­—é‡å¿…é¡»åœ¨ **25 åˆ° 35 ä¸ªæ±‰å­—** ä¹‹é—´ã€‚
   - ç»å¯¹ä¸¥ç¦è¶…è¿‡ 40 å­—ï¼ˆå› ä¸º 5 ç§’å†…è¯»ä¸å®Œï¼Œè§†é¢‘ä¹Ÿæ”¾ä¸ä¸‹ï¼‰ã€‚
   - å¦‚æœåŸæ–‡ä¸€å¥è¯åªæœ‰ 10 ä¸ªå­—ï¼Œè¯·è§‚å¯Ÿä¸‹ä¸€å¥ï¼Œè‹¥ä¸‹ä¸€å¥ä¹Ÿæ˜¯çŸ­å¥ä¸”é€»è¾‘è¿è´¯ï¼Œè¯·åˆå¹¶ï¼Œä½¿æ€»å­—æ•°è¾¾åˆ° 25-35 å­—ã€‚
   - å¦‚æœåŸæ–‡ä¸€å¥è¯æœ‰ 60 ä¸ªå­—ï¼Œå¿…é¡»åœ¨ä¸­é—´è¯­ä¹‰åœé¡¿å¤„å¼ºè¡Œåˆ‡åˆ†ä¸ºä¸¤ä¸ªåˆ†é•œã€‚

2. **åŠ¨ä½œå®¹é‡é™åˆ¶**ï¼š
   - ä¸€ä¸ªåˆ†é•œåªèƒ½åŒ…å«ã€ä¸€ä¸ªæ ¸å¿ƒåŠ¨ä½œã€‘ï¼ˆå¦‚ï¼šæ¨é—¨ã€å›å¤´ã€æµæ³ªã€å¥”è·‘ï¼‰ã€‚
   - ç¦æ­¢åœ¨ä¸€ä¸ªåˆ†é•œï¼ˆ5ç§’ï¼‰å†…å¡å…¥å¤šä¸ªå¤æ‚åŠ¨ä½œã€‚

3. **é›¶å¢åˆ æ”¹**ï¼š
   - ä¸¥ç¦æ”¹åŠ¨åŸæ–‡ä»»ä½•å­—è¯ã€‚
   - è¾“å‡ºæ ¼å¼ï¼š[åºå·]. [æ–‡æ¡ˆ]

### é€»è¾‘ç¤ºä¾‹ï¼š
åŸæ–‡ï¼šä»–å¤±é­‚è½é­„åœ°èµ°åœ¨è¡—ä¸Šï¼Œå¤©ç©ºçªç„¶ä¸‹èµ·äº†å¤§é›¨ï¼Œä»–æŠ¬å¤´çœ‹å¤©ï¼Œä»»ç”±é›¨æ°´å†²åˆ·ã€‚
åˆ†é•œç»“æœï¼š
1.ä»–å¤±é­‚è½é­„åœ°èµ°åœ¨è¡—ä¸Šï¼Œå¤©ç©ºçªç„¶ä¸‹èµ·äº†å¤§é›¨ã€‚ï¼ˆ23å­—ï¼Œä¸€ä¸ªç¯å¢ƒæ”¹å˜ï¼‰
2.ä»–æŠ¬å¤´çœ‹å¤©ï¼Œä»»ç”±é›¨æ°´å†²åˆ·ã€‚ï¼ˆ12å­—ï¼Œä¸ºäº†ä¿è¯ç”»é¢æ„Ÿï¼Œæ­¤å¤„è™½çŸ­ä½†ä¸ºé‡ç‚¹åŠ¨ä½œï¼Œå¯ç‹¬ç«‹ï¼‰
"""

        with st.spinner("æ­£åœ¨è®¡ç®—å­—æ•°å¹¶è§„åˆ’å™äº‹èŠ‚å¥..."):
            response = client.chat.completions.create(
                model=model_id,
                messages=[{"role": "system", "content": STEP1_PROMPT},
                          {"role": "user", "content": clean_stream}],
                temperature=0.1
            )
            st.session_state['step1_result'] = response.choices[0].message.content

# å±•ç¤ºå¹¶å¢åŠ å­—æ•°ç»Ÿè®¡
if st.session_state['step1_result']:
    st.subheader("ğŸ“‹ å¯¼æ¼”åˆ†é•œè‰æ¡ˆï¼ˆé™„å­—æ•°æ£€æŸ¥ï¼‰")
    
    # è§£æåˆ†é•œå¹¶å®æ—¶è®¡ç®—å­—æ•°
    lines = st.session_state['step1_result'].split('\n')
    for line in lines:
        if line.strip():
            # æå–æ–‡å­—å†…å®¹ï¼ˆå»æ‰åºå·ï¼‰
            text_only = re.sub(r'^\d+[\.ã€\s]+', '', line)
            count = len(text_only)
            if count > 40:
                st.error(f"âš ï¸ åˆ†é•œè¿‡é•¿ ({count}å­—)ï¼š{line}")
            elif count < 15:
                st.warning(f"âš ï¸ åˆ†é•œè¿‡çŸ­ ({count}å­—)ï¼š{line}")
            else:
                st.success(f"âœ… èŠ‚å¥å®Œç¾ ({count}å­—)ï¼š{line}")

    st.session_state['step1_result'] = st.text_area("åœ¨æ­¤æ‰‹åŠ¨å¾®è°ƒåˆ†é•œ", st.session_state['step1_result'], height=300)

    st.markdown("---")

    # --- ç¬¬äºŒé˜¶æ®µï¼šè§†è§‰æè¿° ---
    st.header("ç¬¬äºŒæ­¥ï¼šè§†è§‰æ‰©å……ï¼ˆMJ + å³æ¢¦ï¼‰")
    char_desc = st.text_area("ğŸ‘¤ è§’è‰²åŠç€è£…æ ¸å¿ƒè®¾å®š", placeholder="ä¾‹ï¼šæ—å‡¡ï¼š25å²ï¼Œç„è‰²é•¿è¢ï¼Œç›®å…‰å¦‚ç”µã€‚")

    if st.button("ğŸ¨ ç”Ÿæˆå…¨å¥—è§†è§‰æè¿°è¯", use_container_width=True):
        client = OpenAI(api_key=api_key, base_url=base_url)
        STEP2_PROMPT = f"""ä½ æ˜¯ä¸€ä¸ªç”µå½±è§†è§‰å¯¼æ¼”ã€‚è¯·ä¸ºåˆ†é•œæ–‡æ¡ˆé…ä¸Šè§†è§‰æè¿°ã€‚
        è§’è‰²è®¾å®šï¼š{char_info if 'char_info' in locals() else char_desc}
        
        è¦æ±‚ï¼š
        1. ç”»é¢æè¿°ï¼šé™æ€ã€ç¯å¢ƒã€å…‰å½±ã€‚
        2. è§†é¢‘ç”Ÿæˆï¼šæè¿°åˆ†é•œå†…å”¯ä¸€çš„é‚£ä¸ªåŠ¨ä½œï¼Œç¡®ä¿5ç§’å†…èƒ½åšå®Œã€‚
        3. æ ¼å¼ï¼š[åºå·]. [åŸæ–‡]\nç”»é¢æè¿°ï¼š...\nè§†é¢‘ç”Ÿæˆï¼š...\n---"""
        
        with st.spinner("æ­£åœ¨ç”Ÿæˆæç¤ºè¯..."):
            response = client.chat.completions.create(
                model=model_id,
                messages=[{"role": "system", "content": STEP2_PROMPT},
                          {"role": "user", "content": st.session_state['step1_result']}],
                temperature=0.4
            )
            st.write(response.choices[0].message.content)
