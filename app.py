import streamlit as st
import requests
import json

# ==========================================
# æ ¸å¿ƒå‡½æ•°ï¼šAI è°ƒç”¨é€»è¾‘
# ==========================================

def call_ai(provider, key, mid, base_url, prompt):
    key = key.strip()
    default_models = {
        "DeepSeek": "deepseek-chat",
        "ChatGPT": "gpt-4o",
        "Gemini": "gemini-1.5-pro",
        "Grok (xAI)": "grok-beta",
        "ç¬¬ä¸‰æ–¹ä¸­è½¬ (OpenAIæ ¼å¼)": "gpt-4o"
    }
    target_model = mid if mid else default_models.get(provider, "")

    if provider == "ç¬¬ä¸‰æ–¹ä¸­è½¬ (OpenAIæ ¼å¼)":
        url = base_url.rstrip('/')
        if not url.endswith('/chat/completions'): url += '/chat/completions'
    else:
        urls = {
            "DeepSeek": "https://api.deepseek.com/chat/completions",
            "ChatGPT": "https://api.openai.com/v1/chat/completions",
            "Gemini": "https://generativelanguage.googleapis.com/v1beta/openai/chat/completions",
            "Grok (xAI)": "https://api.x.ai/v1/chat/completions",
            "è±†åŒ… (ç«å±±å¼•æ“)": "https://ark.cn-beijing.volces.com/api/v3/chat/completions"
        }
        url = urls.get(provider)

    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {key}"}
    payload = {
        "model": target_model,
        "messages": [{"role": "system", "content": "ä½ æ˜¯ä¸€ä½æ¼«å‰§å¯¼æ¼”ï¼Œè´Ÿè´£å°†å‰§æœ¬ç»†åŒ–ä¸ºMJç”»é¢æè¿°ä¸å³æ¢¦è§†é¢‘æŒ‡ä»¤ã€‚"}, {"role": "user", "content": prompt}],
        "temperature": 0.2
    }
    
    try:
        final_url = f"{url}?key={key}" if provider == "Gemini" and "key=" not in url else url
        response = requests.post(final_url, headers=headers, json=payload, timeout=120)
        if response.status_code != 200:
            return f"API é”™è¯¯: {response.text}"
        return response.json()['choices'][0]['message']['content']
    except Exception as e:
        return f"è¯·æ±‚å¼‚å¸¸: {str(e)}"

# ==========================================
# ç•Œé¢å¸ƒå±€ä¸ Session çŠ¶æ€ç®¡ç†
# ==========================================

st.set_page_config(page_title="æ¼«å‰§å¤§å¸ˆ v2.6 - æ–­ç‚¹æ‰¹å¤„ç†ç‰ˆ", layout="wide")

# åˆå§‹åŒ–çŠ¶æ€
if 'step1_list' not in st.session_state: st.session_state.step1_list = []
if 'current_index' not in st.session_state: st.session_state.current_index = 0
if 'accumulated_storyboard' not in st.session_state: st.session_state.accumulated_storyboard = ""
if 'last_batch_result' not in st.session_state: st.session_state.last_batch_result = ""

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("âš™ï¸ 1. API å¼•æ“")
    provider = st.selectbox("é€‰æ‹©ä¾›åº”å•†", ["ç¬¬ä¸‰æ–¹ä¸­è½¬ (OpenAIæ ¼å¼)", "DeepSeek", "ChatGPT", "Gemini", "Grok (xAI)", "è±†åŒ… (ç«å±±å¼•æ“)"])
    custom_base = st.text_input("API Base URL", value="https://blog.tuiwen.xyz/v1") if provider == "ç¬¬ä¸‰æ–¹ä¸­è½¬ (OpenAIæ ¼å¼)" else ""
    api_key = st.text_input("API Key", type="password")
    model_id = st.text_input("Model ID", value="gpt-4o")
    
    st.divider()
    st.header("ğŸ‘¤ 2. äººç‰©è®¾å®šåº“")
    char_setup = st.text_area("äººç‰©è§’è‰²æè¿°è¯ (å§“åï¼š(æè¿°è¯))", height=300, 
                               placeholder="å®‰å¦™è¡£ï¼š(æè¿°å†…å®¹...)\nèµµå°˜ï¼š(æè¿°å†…å®¹...)")
    
    if st.button("ğŸ”´ é‡ç½®æ‰€æœ‰è¿›åº¦"):
        st.session_state.current_index = 0
        st.session_state.accumulated_storyboard = ""
        st.session_state.last_batch_result = ""
        st.rerun()

# --- ä¸»ç•Œé¢ ---
st.title("ğŸ¬ æ¼«å‰§å…¨æµç¨‹åˆ†é•œç«™ (æ–­ç‚¹å¼ç”Ÿæˆ)")

tab1, tab2 = st.tabs(["ç¬¬ä¸€æ­¥ï¼šé€»è¾‘åˆ‡åˆ†", "ç¬¬äºŒæ­¥ï¼šåˆ†æ®µç”Ÿæˆè§†è§‰æŒ‡ä»¤"])

# --- ç¬¬ä¸€æ­¥ï¼šé€»è¾‘åˆ‡åˆ† ---
with tab1:
    st.subheader("ğŸ–‹ï¸ å‰§æœ¬é€»è¾‘å¤„ç† (æ¯æ¡ä¸è¶…35å­—)")
    raw_script = st.text_area("è¾“å…¥åŸå§‹å‰§æœ¬", height=250)
    
    if st.button("å¼€å§‹åˆ†é•œæ‹†åˆ†"):
        prompt_split = f"""
        ä»»åŠ¡ï¼šå°†ä»¥ä¸‹å‰§æœ¬æ‹†åˆ†ä¸ºé€»è¾‘è¿è´¯çš„åˆ†é•œã€‚
        è§„åˆ™ï¼š
        1. é€»è¾‘åˆå¹¶ï¼šå°†åŒä¸€åœºæ™¯ã€è¿è´¯åŠ¨ä½œçš„çŸ­å¥åˆå¹¶ã€‚
        2. æ—¶é•¿é™åˆ¶ï¼šåˆå¹¶åæ¯æ¡æ–‡æ¡ˆä¸¥ç¦è¶…è¿‡35ä¸ªå­—ã€‚
        3. æ ¼å¼ï¼šä»…è¾“å‡º åºå·. [æ–‡æ¡ˆå†…å®¹]
        
        æ–‡æ¡ˆï¼š
        {raw_script}
        """
        with st.spinner("æ­£åœ¨é€»è¾‘åˆ‡åˆ†..."):
            result = call_ai(provider, api_key, model_id, custom_base, prompt_split)
            # å­˜å…¥åˆ—è¡¨ï¼Œè¿‡æ»¤æ‰ç©ºè¡Œ
            st.session_state.step1_list = [line.strip() for line in result.split('\n') if line.strip() and '.' in line]
            st.session_state.current_index = 0 # é‡ç½®ç´¢å¼•
            st.success(f"åˆ‡åˆ†å®Œæˆï¼Œå…± {len(st.session_state.step1_list)} ä¸ªé€»è¾‘åˆ†é•œã€‚")
    
    if st.session_state.step1_list:
        st.write(f"å½“å‰å·²åŠ è½½ {len(st.session_state.step1_list)} æ¡åˆ†é•œæ–‡æ¡ˆã€‚")
        st.text_area("åˆ‡åˆ†åˆ—è¡¨é¢„è§ˆ", value="\n".join(st.session_state.step1_list), height=200)

# --- ç¬¬äºŒæ­¥ï¼šåˆ†æ®µç”Ÿæˆ ---
with tab2:
    st.subheader("ğŸ–¼ï¸ è§†è§‰æè¿°ç”Ÿæˆ (åˆ†æ®µæ§åˆ¶)")
    
    if not st.session_state.step1_list:
        st.info("è¯·å…ˆåœ¨â€˜ç¬¬ä¸€æ­¥â€™å®Œæˆåˆ†é•œæ‹†åˆ†ã€‚")
    else:
        total = len(st.session_state.step1_list)
        current = st.session_state.current_index
        
        # è¿›åº¦æ˜¾ç¤º
        st.progress(current / total if total > 0 else 0)
        st.write(f"ğŸ“Š å½“å‰è¿›åº¦ï¼šç¬¬ **{current}** é•œ / å…± {total} é•œ")

        col1, col2 = st.columns(2)
        with col1:
            batch_size = st.number_input("æ¯æ¬¡ç”Ÿæˆåˆ†é•œæ•°", min_value=1, max_value=50, value=20)
        
        # æ£€æŸ¥æ˜¯å¦å¤„ç†å®Œæ¯•
        if current < total:
            if st.button(f"ğŸš€ ç”Ÿæˆæ¥ä¸‹æ¥çš„ {batch_size} ç»„æè¿°"):
                end_index = min(current + batch_size, total)
                batch_data = st.session_state.step1_list[current:end_index]
                batch_text = "\n".join(batch_data)
                
                prompt_visual = f"""
                ä½ æ˜¯ä¸€ä½æ¼«å‰§è§†è§‰å¯¼æ¼”ã€‚è¯·ä¸ºä»¥ä¸‹åˆ†é•œç”Ÿæˆå¯¹åº”çš„ MJ ç”»é¢æè¿° å’Œ å³æ¢¦è§†é¢‘ç”ŸæˆæŒ‡ä»¤ã€‚
                
                ã€æ ¸å¿ƒè§’è‰²åº“ã€‘ï¼š
                {char_setup}
                
                ã€æœ¬æ¬¡åˆ†é•œåˆ—è¡¨ã€‘ï¼š
                {batch_text}
                
                ã€è¾“å‡ºè¦æ±‚ã€‘ï¼š
                1. æ ¼å¼ï¼š
                   åºå·. [åŸæ–‡æ¡ˆå¯¹æ¯”]
                   ç”»é¢æè¿°ï¼š[åœºæ™¯ã€æ™¯åˆ«ã€è§†è§’]ï¼Œè§’è‰²å(å®Œæ•´æè¿°è¯)ï¼Œè§’è‰²å(å®Œæ•´æè¿°è¯)... [é™æ€æ„å›¾ä¸å…‰å½±]
                   è§†é¢‘ç”Ÿæˆï¼š[å…·ä½“åŠ¨æ€è¡Œä¸ºä¸è¡¨æƒ…]ï¼Œ[é•œå¤´è¯­è¨€æè¿°]
                
                2. äººç‰©æ³¨å…¥ï¼šå¿…é¡»åœ¨è§’è‰²ååç´§è·Ÿæ‹¬å·å†…çš„å®Œæ•´æè¿°è¯ã€‚
                3. æ¯ä¸€é•œå¼€å¤´å¿…é¡»æè¿°å…·ä½“çš„åœºæ™¯èƒŒæ™¯ä»¥ä¿è¯ä¸€è‡´æ€§ã€‚
                """
                
                with st.spinner(f"æ­£åœ¨ç”Ÿæˆ {current+1} åˆ° {end_index} é•œ..."):
                    batch_result = call_ai(provider, api_key, model_id, custom_base, prompt_visual)
                    st.session_state.last_batch_result = batch_result
                    st.session_state.accumulated_storyboard += "\n\n" + batch_result
                    st.session_state.current_index = end_index
                    st.rerun() # åˆ·æ–°ç•Œé¢æ˜¾ç¤ºç»“æœ
        else:
            st.success("âœ… å…¨éƒ¨ 600+ åˆ†é•œå·²å®Œæˆç”Ÿæˆï¼")

        # å±•ç¤ºæœ€è¿‘ä¸€æ¬¡ç”Ÿæˆçš„ç»“æœ
        if st.session_state.last_batch_result:
            with st.expander("âœ¨ æŸ¥çœ‹æœ€è¿‘ç”Ÿæˆçš„ 20 ç»„ç»“æœ", expanded=True):
                st.markdown(st.session_state.last_batch_result)

        st.divider()
        st.subheader("ğŸ“ å·²ç”Ÿæˆçš„å…¨é‡è„šæœ¬æ±‡æ€»")
        st.text_area("å…¨é‡æ•°æ® (å¯ç›´æ¥å¤åˆ¶)", value=st.session_state.accumulated_storyboard, height=400)
        
        if st.session_state.accumulated_storyboard:
            st.download_button("ğŸ’¾ ä¸‹è½½å·²ç”Ÿæˆçš„éƒ¨åˆ†è„šæœ¬", 
                               st.session_state.accumulated_storyboard, 
                               file_name=f"Storyboard_Progress_{current}.txt")
