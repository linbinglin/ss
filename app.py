import streamlit as st
import requests
import json

# é¡µé¢åŸºç¡€é…ç½®
st.set_page_config(page_title="æ¼«å‰§å…¨æµç¨‹åˆ†é•œå·¥å…·V3", layout="wide")

# --- ä¾§è¾¹æ ï¼šAPI ä¸æ¨¡å‹é…ç½® ---
st.sidebar.header("ğŸš€ æ ¸å¿ƒ API é…ç½®")
api_base = st.sidebar.text_input("æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1/chat/completions")
api_key = st.sidebar.text_input("API Key", type="password")

model_list = ["deepseek-chat", "gpt-4o", "claude-3-5-sonnet-20240620", "gemini-1.5-pro", "grok-1", "doubao-pro-4k", "è‡ªå®šä¹‰"]
selected_model = st.sidebar.selectbox("é€‰æ‹©æ¨¡å‹", model_list)
model_id = st.sidebar.text_input("æ‰‹åŠ¨è¾“å…¥ Model ID") if selected_model == "è‡ªå®šä¹‰" else selected_model

# --- ä¸»ç•Œé¢ ---
st.title("ğŸ¬ æ¼«å‰§å…¨æµç¨‹åˆ†é•œå¤„ç†ç³»ç»Ÿ")
st.markdown("---")

# åˆå§‹åŒ– Session State
if 'split_result' not in st.session_state:
    st.session_state.split_result = ""
if 'visual_results' not in st.session_state:
    st.session_state.visual_results = []

# å®šä¹‰ Tab
tab1, tab2 = st.tabs(["ğŸ“ ç¬¬ä¸€æ­¥ï¼šæ–‡æ¡ˆé€»è¾‘åˆ‡åˆ†", "ğŸ¨ ç¬¬äºŒæ­¥ï¼šåˆ†æ‰¹è§†è§‰æè¿°è¯ç”Ÿæˆ"])

# --- Tab 1: æ–‡æ¡ˆåˆ‡åˆ†é€»è¾‘ ---
with tab1:
    st.subheader("æ–‡æ¡ˆè‡ªåŠ¨åˆ‡åˆ† (35å­—/åŠ¨ä½œ/å¯¹è¯åŸåˆ™)")
    st.info("AI å°†ä¸¥æ ¼æŒ‰ç…§äººç‰©åˆ‡æ¢ã€åŠ¨ä½œæ”¹å˜åŠå­—æ•°é™åˆ¶ï¼ˆ35å­—å†…/5ç§’è§†é¢‘ï¼‰è¿›è¡Œåˆ‡åˆ†ï¼Œä¸æ¼ä¸€ä¸ªå­—ã€‚")
    
    col_char, col_text = st.columns([1, 2])
    with col_char:
        char_desc = st.text_area("è§’è‰²å¤–è§‚å­—å…¸ (å¿…å¡«)", height=150, help="æè¿°è§’è‰²å¤–è§‚ç€è£…ï¼Œç”¨äºç¬¬äºŒæ­¥æ³¨å…¥", 
                                placeholder="èµµå°˜ï¼šç„è‰²é•¿è¢ï¼Œè…°é—´ä½©ç‰...\nå®‰å¦™è¡£ï¼šç™½è‰²è¾«å­ç»«ç½—çº±è¡£ï¼Œé“¶ä¸è´è¶ç°ª...")
    with col_text:
        uploaded_file = st.file_uploader("ä¸Šä¼ åŸæ–‡æ–‡æœ¬ (.txt)", type=['txt'])
        input_raw = st.text_area("æˆ–è€…ç›´æ¥ç²˜è´´åŸæ–‡å†…å®¹", height=250, placeholder="åœ¨æ­¤ç²˜è´´éœ€è¦å¤„ç†çš„æ•…äº‹åŸæ–‡...")

    if st.button("å¼€å§‹è‡ªåŠ¨åŒ–åˆ‡åˆ†åˆ†é•œ", type="primary"):
        source_content = input_raw if input_raw else (uploaded_file.read().decode("utf-8") if uploaded_file else "")
        if not api_key or not source_content:
            st.error("è¯·ç¡®ä¿å¡«å†™äº† API Key å’Œæ–‡æ¡ˆå†…å®¹")
        else:
            with st.spinner("AI æ­£åœ¨æ‰§è¡Œæ·±åº¦åˆ‡åˆ†é€»è¾‘ï¼ˆä¸¥æ ¼æ‰§è¡Œ35å­—åŸåˆ™ï¼‰..."):
                split_prompt = """ä½ æ˜¯ä¸€ä¸ªé¡¶çº§æ¼«å‰§ç¼–å‰§ã€‚
                ä»»åŠ¡ï¼šå°†æ–‡æ¡ˆä¸¥æ ¼æ‹†åˆ†ä¸ºç‹¬ç«‹åˆ†é•œã€‚
                
                ä¸¥æ ¼å‡†åˆ™ï¼š
                1. å¯¹è¯åˆ‡æ¢å¿…åˆ†ï¼šä¸åŒäººè¯´è¯å¿…é¡»æ˜¯ç‹¬ç«‹åˆ†é•œã€‚
                2. åŠ¨ä½œæ”¹å˜å¿…åˆ†ï¼šå¦‚ä»â€œåç€â€åˆ°â€œèµ·èº«â€ï¼Œå¿…é¡»åˆ‡åˆ†ã€‚
                3. åœºæ™¯è½¬æ¢å¿…åˆ†ã€‚
                4. å­—æ•°å¼ºåˆ¶é™åˆ¶ï¼šæ–‡æ¡ˆæ¯æ®µå­—æ•°æ§åˆ¶åœ¨30-35å­—ä»¥å†…ï¼ˆå¯¹åº”5ç§’é…éŸ³ï¼‰ã€‚è‹¥åŸæ–‡ä¸€æ®µè¯è¿‡é•¿ï¼Œå¿…é¡»ä»è¯­ä¹‰åœé¡¿å¤„å¼ºåˆ¶æ‹†åˆ†ä¸ºå¤šä¸ªåˆ†é•œã€‚
                5. åŸæ–‡å®Œæ•´ï¼šä¸¥ç¦é—æ¼ä»»ä½•ä¸€ä¸ªå­—ï¼Œä¸¥ç¦ä¿®æ”¹ä»»ä½•åŸæ–‡è¯è¯­ï¼Œä¸¥ç¦æ·»åŠ æè¿°è¯ã€‚
                
                è¾“å‡ºæ ¼å¼èŒƒä¾‹ï¼š
                1.åŸæ–‡å†…å®¹...
                2.åŸæ–‡å†…å®¹...
                """
                try:
                    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
                    data = {
                        "model": model_id,
                        "messages": [{"role": "system", "content": split_prompt}, {"role": "user", "content": source_content}],
                        "temperature": 0.1
                    }
                    res = requests.post(api_base, headers=headers, json=data)
                    res.raise_for_status()
                    st.session_state.split_result = res.json()['choices'][0]['message']['content']
                    st.session_state.char_desc_stored = char_desc
                    st.success("åˆ‡åˆ†å®Œæˆï¼è¯·åœ¨ä¸‹æ–¹æ ¸å¯¹å¹¶å¾®è°ƒã€‚")
                except Exception as e:
                    st.error(f"åˆ‡åˆ†å¤±è´¥: {e}")

    # æ˜¾ç¤ºå¹¶å…è®¸æ‰‹åŠ¨ç¼–è¾‘åˆ‡åˆ†ç»“æœ
    if st.session_state.split_result:
        st.write("### é€»è¾‘åˆ†é•œé¢„è§ˆ (å¯åœ¨æ­¤å¾®è°ƒåºå·å’Œå†…å®¹)")
        st.session_state.split_result = st.text_area("ç¼–è¾‘åˆ†é•œé¢„è§ˆ", value=st.session_state.split_result, height=400)

# --- Tab 2: åˆ†æ‰¹è§†è§‰æè¿°ç”Ÿæˆ ---
with tab2:
    st.subheader("è§†è§‰æç¤ºè¯åˆ†æ‰¹ç”Ÿæˆ (MJå›¾ç‰‡ + å³æ¢¦è§†é¢‘)")
    
    if not st.session_state.split_result:
        st.warning("è¯·å…ˆåœ¨ç¬¬ä¸€ä¸ªæ ‡ç­¾é¡µå®Œæˆâ€˜æ–‡æ¡ˆåˆ‡åˆ†â€™ã€‚")
    else:
        # è§£æåˆ†é•œåˆ—è¡¨
        segments = [s.strip() for s in st.session_state.split_result.split('\n') if s.strip()]
        total_count = len(segments)
        st.write(f"æ£€æµ‹åˆ°å…± **{total_count}** ä¸ªåˆ†é•œã€‚")
        
        col_set1, col_set2 = st.columns(2)
        with col_set1:
            batch_size = 20
            max_batch = (total_count // batch_size) + (1 if total_count % batch_size > 0 else 0)
            current_batch = st.number_input("é€‰æ‹©å¤„ç†æ‰¹æ¬¡ (æ¯æ‰¹20ä¸ªåˆ†é•œ)", min_value=1, max_value=max_batch, step=1)
        
        start_idx = (current_batch - 1) * batch_size
        end_idx = min(start_idx + batch_size, total_count)
        
        st.info(f"å½“å‰å‡†å¤‡å¤„ç†ç¬¬ {start_idx + 1} åˆ° {end_idx} ç»„åˆ†é•œã€‚")

        if st.button(f"å¼€å§‹ç”Ÿæˆè§†è§‰æè¿°è¯ (æ‰¹æ¬¡ {current_batch})"):
            batch_data = segments[start_idx:end_idx]
            with st.spinner("æ³¨å…¥è§’è‰²å¤–è§‚å­—å…¸ï¼Œæ­£åœ¨ç”ŸæˆåŠ¨é™åˆ†ç¦»æç¤ºè¯..."):
                visual_prompt = f"""ä½ æ˜¯ä¸€ä¸ªè§†è§‰åˆ†é•œä¸“å®¶ã€‚
                ä»»åŠ¡ï¼šä¸ºç»™å‡ºçš„åˆ†é•œæ–‡æ¡ˆç”Ÿæˆ Midjourney(9:16) ç”»é¢å’Œ å³æ¢¦AI è§†é¢‘æè¿°ã€‚
                
                è§’è‰²å¤–è§‚ä¸€è‡´æ€§å­—å…¸ï¼š
                {st.session_state.get('char_desc_stored', '')}
                
                è§„åˆ™ï¼š
                1. ä¸¥ç¦æ¼æ‰åŸæ–‡ä¸­çš„ä»»ä½•å­—ã€‚
                2. ã€ç”»é¢æè¿°ã€‘ï¼šMidjourneyä¸“ç”¨ã€‚æè¿°é™æ€åœºæ™¯ã€å…‰å½±ã€æ„å›¾ã€äººç‰©å¤–è§‚ç»†èŠ‚ã€æœè£…æè´¨ã€‚**ç»å¯¹ä¸èƒ½åŒ…å«ä»»ä½•åŠ¨ä½œåŠ¨ä½œè¯è¯­ï¼ˆå¦‚è·‘ã€è·³ã€å“­ï¼‰**ã€‚è§†è§’é‡‡ç”¨æ¼«å‰§å¸¸ç”¨è§†è§’ï¼ˆå¦‚ï¼šä¸­æ™¯ã€ç‰¹å†™ï¼‰ã€‚
                3. ã€è§†é¢‘ç”Ÿæˆã€‘ï¼šå³æ¢¦AIä¸“ç”¨ã€‚åŸºäºç”»é¢æè¿°ï¼Œå¢åŠ åŠ¨æ€ï¼šåŠ¨ä½œèµ·ä¼ã€ç¥æ€å˜åŒ–ã€é•œå¤´æ¨æ‹‰æ‘‡ç§»ã€‚æè¿°éœ€ä½“ç°æ•…äº‹æ„Ÿã€‚
                
                è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
                [åºå·]
                åŸæ–‡å†…å®¹ï¼š...
                ç”»é¢æè¿°ï¼š...
                è§†é¢‘ç”Ÿæˆï¼š...
                ---
                """
                try:
                    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
                    data = {
                        "model": model_id,
                        "messages": [
                            {"role": "system", "content": visual_prompt},
                            {"role": "user", "content": "\n".join(batch_data)}
                        ],
                        "temperature": 0.3
                    }
                    res = requests.post(api_base, headers=headers, json=data)
                    res.raise_for_status()
                    batch_res = res.json()['choices'][0]['message']['content']
                    st.session_state.current_visual_batch = batch_res
                except Exception as e:
                    st.error(f"æè¿°ç”Ÿæˆå¤±è´¥: {e}")

        # æ˜¾ç¤ºæ‰¹æ¬¡ç”Ÿæˆç»“æœ
        if 'current_visual_batch' in st.session_state:
            st.write("---")
            st.write(f"### ç¬¬ {current_batch} æ‰¹æ¬¡å¤„ç†ç»“æœ")
            st.text_area("ç”Ÿæˆçš„è§†è§‰æç¤ºè¯ç»“æœ", value=st.session_state.current_visual_batch, height=500)
            st.download_button(f"ä¸‹è½½ç¬¬ {current_batch} æ‰¹æ¬¡åˆ†é•œ", 
                             st.session_state.current_visual_batch, 
                             file_name=f"åˆ†é•œæè¿°_æ‰¹æ¬¡{current_batch}.txt")
