import streamlit as st
import requests
import json
import re

# ==========================================
# æ ¸å¿ƒå‡½æ•°ï¼šAI è°ƒç”¨é€»è¾‘
# ==========================================

def call_ai(provider, key, mid, base_url, prompt):
    key = key.strip()
    default_models = {
        "DeepSeek": "deepseek-chat",
        "ChatGPT": "gpt-4o",
        "Gemini": "gemini-1.5-pro",
        "Grok (xAI)": "grok-beta",
        "ç¬¬ä¸‰æ–¹ä¸­è½¬ (OpenAIæ ¼å¼)": "gpt-4o"
    }
    target_model = mid if mid else default_models.get(provider, "")

    if provider == "ç¬¬ä¸‰æ–¹ä¸­è½¬ (OpenAIæ ¼å¼)":
        url = base_url.rstrip('/')
        if not url.endswith('/chat/completions'): url += '/chat/completions'
    else:
        urls = {
            "DeepSeek": "https://api.deepseek.com/chat/completions",
            "ChatGPT": "https://api.openai.com/v1/chat/completions",
            "Gemini": "https://generativelanguage.googleapis.com/v1beta/openai/chat/completions",
            "Grok (xAI)": "https://api.x.ai/v1/chat/completions",
            "è±†åŒ… (ç«å±±å¼•æ“)": "https://ark.cn-beijing.volces.com/api/v3/chat/completions"
        }
        url = urls.get(provider)

    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {key}"}
    payload = {
        "model": target_model,
        "messages": [{"role": "system", "content": "ä½ æ˜¯ä¸€ä½æ¼«å‰§å¯¼æ¼”ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§æ ¼å¼è¾“å‡ºã€‚ä¸è¦è¯´ä»»ä½•åºŸè¯ã€‚"}, {"role": "user", "content": prompt}],
        "temperature": 0.2
    }
    
    try:
        final_url = f"{url}?key={key}" if provider == "Gemini" and "key=" not in url else url
        response = requests.post(final_url, headers=headers, json=payload, timeout=120)
        if response.status_code != 200:
            return f"API é”™è¯¯: {response.text}"
        return response.json()['choices'][0]['message']['content']
    except Exception as e:
        return f"è¯·æ±‚å¼‚å¸¸: {str(e)}"

# ==========================================
# ç•Œé¢å¸ƒå±€ä¸çŠ¶æ€ç®¡ç†
# ==========================================

st.set_page_config(page_title="æ¼«å‰§å¤§å¸ˆ v2.7 - é²æ£’æ€§ä¿®å¤ç‰ˆ", layout="wide")

if 'step1_list' not in st.session_state: st.session_state.step1_list = []
if 'current_index' not in st.session_state: st.session_state.current_index = 0
if 'accumulated_storyboard' not in st.session_state: st.session_state.accumulated_storyboard = ""

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("âš™ï¸ 1. API å¼•æ“")
    provider = st.selectbox("é€‰æ‹©ä¾›åº”å•†", ["ç¬¬ä¸‰æ–¹ä¸­è½¬ (OpenAIæ ¼å¼)", "DeepSeek", "ChatGPT", "Gemini", "Grok (xAI)", "è±†åŒ… (ç«å±±å¼•æ“)"])
    custom_base = st.text_input("API Base URL", value="https://blog.tuiwen.xyz/v1") if provider == "ç¬¬ä¸‰æ–¹ä¸­è½¬ (OpenAIæ ¼å¼)" else ""
    api_key = st.text_input("API Key", type="password")
    model_id = st.text_input("Model ID", value="gpt-4o")
    
    st.divider()
    st.header("ğŸ‘¤ 2. äººç‰©è®¾å®šåº“")
    char_setup = st.text_area("äººç‰©è®¾å®š (å§“åï¼š(æè¿°))", height=300)
    
    if st.button("ğŸ”´ é‡ç½®è¿›åº¦"):
        st.session_state.current_index = 0
        st.session_state.accumulated_storyboard = ""
        st.session_state.step1_list = []
        st.rerun()

# --- ä¸»ç•Œé¢ ---
st.title("ğŸ¬ æ¼«å‰§å¤§å¸ˆ v2.7")

tab1, tab2 = st.tabs(["ç¬¬ä¸€æ­¥ï¼šé€»è¾‘åˆ†é•œæ‹†åˆ†", "ç¬¬äºŒæ­¥ï¼šåˆ†æ®µç”Ÿæˆè§†è§‰è„šæœ¬"])

# --- ç¬¬ä¸€æ­¥ï¼šé€»è¾‘åˆ‡åˆ†ä¿®å¤ç‰ˆ ---
with tab1:
    st.subheader("ğŸ–‹ï¸ å‰§æœ¬é€»è¾‘æ‹†åˆ†")
    raw_script = st.text_area("è¾“å…¥åŸå§‹å‰§æœ¬", height=250)
    
    if st.button("å¼€å§‹åˆ†é•œæ‹†åˆ†"):
        prompt_split = f"""
        ä»»åŠ¡ï¼šå°†å‰§æœ¬æ‹†åˆ†ä¸ºé€‚åˆæ¼«å‰§çš„åˆ†é•œã€‚
        
        è¦æ±‚ï¼š
        1. æ¯ä¸€ä¸ªåˆ†é•œæ–‡æ¡ˆä¸¥æ ¼ç¦æ­¢è¶…è¿‡ 35 ä¸ªæ±‰å­—ã€‚
        2. åŒåœºæ™¯ã€è¿è´¯åŠ¨ä½œè¯·åˆå¹¶ã€‚
        3. å¯¹è¯åˆ‡æ¢ã€å¤§åŠ¨ä½œå¿…é¡»æ‹†åˆ†ã€‚
        4. ç¦æ­¢é—æ¼åŸæ–‡ä»»ä½•å­—ã€‚
        5. æ ¼å¼è¦æ±‚ï¼šåºå·. [æ–‡æ¡ˆå†…å®¹]
           ä¾‹å¦‚ï¼š
           1. [æˆ‘æ˜¯åæ»¡äº¬åŸçš„ç¥ç§˜ç”»å¸ˆï¼Œä¸€ç¬”ä¸€åˆ’çš†èƒ½å‹¾åŠ¨ç”·å­æƒ…æ¬²ã€‚]
           2. [ä¸–é—´å¥³å­éª‚æˆ‘ä¼¤é£è´¥ä¿—ï¼Œå¯ç”·äººä»¬å´è§†è‹¥çå®ã€‚]
        
        å¾…å¤„ç†å‰§æœ¬ï¼š
        {raw_script}
        """
        with st.spinner("AI æ­£åœ¨æ€è€ƒé€»è¾‘åˆ†é•œ..."):
            result = call_ai(provider, api_key, model_id, custom_base, prompt_split)
            
            # ä¼˜åŒ–è§£æé€»è¾‘ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… "æ•°å­—. [å†…å®¹]" æˆ– "æ•°å­—ã€[å†…å®¹]"
            lines = result.split('\n')
            new_list = []
            for line in lines:
                line = line.strip()
                if re.match(r"^\d+[\.ï¼ã€\s]", line): # åŒ¹é…æ•°å­—å¼€å¤´åæ¥æ ‡ç‚¹æˆ–ç©ºæ ¼
                    new_list.append(line)
            
            if not new_list:
                st.error("è§£æå¤±è´¥ï¼AI è¿”å›çš„å†…å®¹æ ¼å¼ä¸æ­£ç¡®ã€‚è¯·æŸ¥çœ‹ä¸‹æ–¹ AI çš„åŸå§‹å›å¤å¹¶å°è¯•é‡æ–°ç”Ÿæˆã€‚")
                with st.expander("æŸ¥çœ‹ AI åŸå§‹å›å¤"):
                    st.code(result)
            else:
                st.session_state.step1_list = new_list
                st.session_state.current_index = 0
                st.success(f"æˆåŠŸæ‹†åˆ†å‡º {len(new_list)} ä¸ªåˆ†é•œï¼")

    if st.session_state.step1_list:
        st.text_area("å½“å‰åˆ†é•œé¢„è§ˆ", value="\n".join(st.session_state.step1_list), height=300)

# --- ç¬¬äºŒæ­¥ï¼šåˆ†æ®µç”Ÿæˆè§†è§‰æŒ‡ä»¤ ---
with tab2:
    st.subheader("ğŸ–¼ï¸ è§†è§‰æŒ‡ä»¤ç”Ÿæˆ (æ–­ç‚¹æ§åˆ¶)")
    
    if not st.session_state.step1_list:
        st.info("è¯·å…ˆåœ¨â€˜ç¬¬ä¸€æ­¥â€™å®Œæˆæ‹†åˆ†ã€‚")
    else:
        current = st.session_state.current_index
        total = len(st.session_state.step1_list)
        st.progress(current / total)
        st.write(f"ğŸ“Š è¿›åº¦ï¼š{current} / {total}")

        batch_size = st.number_input("æ¯æ¬¡ç”Ÿæˆæ•°é‡", 1, 50, 20)
        
        if current < total:
            if st.button(f"ğŸš€ ç”Ÿæˆæ¥ä¸‹æ¥çš„ {batch_size} ç»„"):
                end = min(current + batch_size, total)
                batch_data = "\n".join(st.session_state.step1_list[current:end])
                
                prompt_visual = f"""
                ä»»åŠ¡ï¼šä¸ºä»¥ä¸‹åˆ†é•œç”Ÿæˆè§†è§‰è„šæœ¬ã€‚
                
                ã€äººç‰©è®¾å®šã€‘ï¼š
                {char_setup}
                
                ã€æœ¬æ‰¹æ¬¡åˆ†é•œã€‘ï¼š
                {batch_data}
                
                ã€è¾“å‡ºæ ¼å¼ã€‘ï¼š
                åºå·. [åŸæ–‡æ¡ˆå¯¹æ¯”]
                ç”»é¢æè¿°ï¼š[åœºæ™¯ã€æ™¯åˆ«ã€è§†è§’]ï¼Œå§“å(å®Œæ•´æè¿°)ï¼Œå§“å(å®Œæ•´æè¿°)... [é™æ€æ„å›¾ä¸å…‰å½±]
                è§†é¢‘ç”Ÿæˆï¼š[åŠ¨æ€åŠ¨ä½œä¸è¡¨æƒ…å˜åŒ–]ï¼Œ[é•œå¤´è¿åŠ¨è¯­è¨€]
                
                æ³¨æ„ï¼šäººç‰©æè¿°è¯å¿…é¡»ç”¨()æ‰©èµ·æ¥ã€‚æ¯ä¸€ç»„å¿…é¡»åŒ…å«åŸæ–‡æ¡ˆå¯¹ç…§ã€‚
                """
                
                with st.spinner("æ­£åœ¨ç”Ÿæˆæè¿°è¯..."):
                    batch_res = call_ai(provider, api_key, model_id, custom_base, prompt_visual)
                    st.session_state.accumulated_storyboard += "\n\n" + batch_res
