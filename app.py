import streamlit as st
from openai import OpenAI
import re

# 1. é¡µé¢é…ç½®
st.set_page_config(page_title="AIåˆ†é•œå¯¼æ¼” v6.7", layout="wide", page_icon="ğŸ¬")

# æ•°æ®æŒä¹…åŒ–
if 'all_segments' not in st.session_state:
    st.session_state['all_segments'] = []
if 'batch_result' not in st.session_state:
    st.session_state['batch_result'] = ""

# 2. ä¾§è¾¹æ ï¼šé…ç½®ä¸­å¿ƒ
st.sidebar.title("âš™ï¸ ç³»ç»Ÿé…ç½®")
api_key = st.sidebar.text_input("1. API Key", type="password")
base_url = st.sidebar.text_input("2. æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")

st.sidebar.markdown("---")
st.sidebar.subheader("3. Midjourney ç”»é£åç¼€")
mj_suffix = st.sidebar.text_input("åç¼€è¯ (å¦‚: --ar 16:9 --v 6.1)", value="--ar 16:9 --v 6.1 --style raw")

st.sidebar.markdown("---")
st.sidebar.subheader("4. æ¨¡å‹è®¾ç½®")
model_options = ["gpt-4o", "claude-3-5-sonnet-20240620", "deepseek-chat", "è‡ªå®šä¹‰æ¨¡å‹"]
selected_option = st.sidebar.selectbox("é€‰æ‹©æ¨¡å‹", model_options)
if selected_option == "è‡ªå®šä¹‰æ¨¡å‹":
    model_id = st.sidebar.text_input("æ‰‹åŠ¨è¾“å…¥ Model ID")
else:
    model_id = selected_option

st.title("ğŸ¬ ç”µå½±è§£è¯´å…¨æµç¨‹åˆ†é•œå·¥å…·")
st.caption("ç¬¬ä¸€æ­¥ï¼šå›å½’ v5.1 é»„é‡‘å¹³è¡¡åˆ‡åˆ† | ç¬¬äºŒæ­¥ï¼šè§†è§‰é”šå®š+æ–‡æ¡ˆå¯¹ç…§+åˆ†æ‰¹ç”Ÿæˆ")

# --- ç¬¬ä¸€é˜¶æ®µï¼šé€»è¾‘åˆ†é•œï¼ˆæ‰¾å› v5.1 å¹³è¡¡æ„Ÿï¼‰ ---
st.header("ç¬¬ä¸€æ­¥ï¼šé€»è¾‘åˆ†é•œï¼ˆç‰©ç†çº§ç²¾å‡†åˆ‡åˆ†ï¼‰")
st.info("ğŸ’¡ **åˆ†é•œé‡‘å¾‹**ï¼šæ¯ä¸ªåˆ†é•œ **25-35å­—**ã€‚ä¸¥ç¦åˆå¹¶ä¸åŒåŠ¨ä½œã€‚ç›®æ ‡æ˜¯ç¡®ä¿ 5ç§’ è§†é¢‘èƒ½å®Œç¾æ‰¿è½½å†…å®¹ã€‚")

uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼ æ–‡æ¡ˆ (TXT)", type=['txt'])

if uploaded_file:
    raw_text = uploaded_file.getvalue().decode("utf-8", errors="ignore")
    # æ ¸å¿ƒé€»è¾‘ï¼šæŠ¹é™¤æ‰€æœ‰æ ¼å¼ï¼Œå¼ºè¿« AI é‡æ–°æµ‹é‡æ–‡å­—é•¿åº¦
    clean_stream = "".join(raw_text.split())

    if st.button("ğŸš€ ç”Ÿæˆé»„é‡‘å¹³è¡¡åˆ†é•œ", use_container_width=True):
        if not api_key or not model_id:
            st.error("è¯·é…ç½® API ä¿¡æ¯")
        else:
            client = OpenAI(api_key=api_key, base_url=base_url)
            
            # ã€å›å½’ v5.1 æ ¸å¿ƒã€‘ç‰©ç†åˆ‡å‰²æŒ‡ä»¤ï¼Œå¼ºåŒ–â€œä¸¥ç¦åˆå¹¶â€å’Œâ€œå­—æ•°åŒºé—´â€
            STEP1_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæå…¶ä¸¥è°¨çš„ç”µå½±åˆ†é•œå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†æä¾›çš„ã€çº¯æ–‡å­—æµã€‘æ‹†è§£ä¸ºã€æ•°å­—ç¼–å·çš„åˆ†é•œè„šæœ¬ã€‘ã€‚

### å¿…é¡»ä¸¥æ ¼éµå®ˆçš„ç‰©ç†åˆ‡åˆ†è§„åˆ™ï¼š
1. **ä¸¥æ ¼ç¼–å·**ï¼šæ¯ä¸€ä¸ªåˆ†é•œå¿…é¡»ä»¥â€œ1.â€ â€œ2.â€ â€œ3.â€ è¿™ç§æ•°å­—åºå·å¼€å¤´ã€‚
2. **æ‹’ç»æ³¨é‡Š**ï¼šä¸¥ç¦æ·»åŠ ä»»ä½•æ‹¬å·ã€æ„å›¾åˆ†ææˆ–æè¿°ï¼Œåªéœ€è¾“å‡ºâ€œæ•°å­—. åŸæ–‡â€ã€‚
3. **è§†è§‰å•å…ƒåˆ‡åˆ†ï¼ˆæ ¸å¿ƒï¼‰**ï¼š
   - ä¸€ä¸ªåˆ†é•œåªèƒ½åŒ…å«ä¸€ä¸ªæ ¸å¿ƒåŠ¨ä½œæˆ–è§†è§‰ç”»é¢ã€‚
   - ã€ä¸¥ç¦åˆå¹¶ã€‘ï¼šå³ä½¿ä¸¤å¥è¯é€»è¾‘ç›¸å…³ï¼Œåªè¦å­—æ•°æ€»å’Œè¶…è¿‡ 35 å­—ï¼Œæˆ–è€…åŒ…å«ä¸¤ä¸ªä¸åŒåŠ¨ä½œï¼ˆå¦‚ï¼šä»–è·‘å›å®¶ã€ä»–åä¸‹ï¼‰ï¼Œå¿…é¡»å¼ºåˆ¶åˆ†ä¸ºä¸¤ä¸ªåˆ†é•œã€‚
4. **é»„é‡‘å­—æ•°åŒºé—´**ï¼š
   - æ¯ä¸ªåˆ†é•œç›®æ ‡å­—æ•°ä¸º **25-35 å­—**ã€‚
   - ç»å¯¹ä¸¥ç¦å•è¡Œè¶…è¿‡ 40 å­—ï¼ˆé…éŸ³ 5 ç§’ä¸Šé™ï¼‰ã€‚
   - å¦‚æœä¸€å¥è¯å¤ªçŸ­ï¼ˆå°äº15å­—ï¼‰ï¼Œå¯ä¸ä¸‹æ–‡åˆå¹¶ï¼Œä½†åˆå¹¶åä¸¥ç¦è¶…è¿‡ 35 å­—ã€‚
5. **åŸæ–‡é›¶æ”¹åŠ¨**ï¼šä¸å‡†æ”¹å­—ã€åˆ å­—ã€åŠ å­—ã€‚
"""
            with st.spinner("æ­£åœ¨æ‰¾å›é»„é‡‘èŠ‚å¥ï¼Œè¿›è¡Œç‰©ç†åˆ‡åˆ†..."):
                try:
                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[{"role": "system", "content": STEP1_PROMPT},
                                  {"role": "user", "content": f"è¯·å¯¹ä»¥ä¸‹æ–‡å­—æµè¿›è¡Œç²¾å‡†çš„ç­‰æƒé‡åˆ†é•œï¼Œå¿…é¡»å¸¦æ•°å­—ç¼–å·ï¼š\n\n{clean_stream}"}],
                        temperature=0.1
                    )
                    st.session_state['all_segments'] = [l.strip() for l in response.choices[0].message.content.split('\n') if re.match(r'^\d+', l.strip())]
                except Exception as e:
                    st.error(f"å¤„ç†å¤±è´¥: {str(e)}")

# ç¬¬ä¸€æ­¥ç»“æœé¢„è§ˆä¸ç»Ÿè®¡
if st.session_state['all_segments']:
    st.subheader(f"ğŸ“‹ åˆ†é•œé¢„è§ˆ (å…± {len(st.session_state['all_segments'])} ç»„)")
    
    col_a, col_b = st.columns([1, 2])
    with col_a:
        # æ˜¾ç¤ºå‰10æ¡çš„å­—æ•°æ£€æµ‹ï¼Œæ–¹ä¾¿ç”¨æˆ·åˆ¤æ–­èŠ‚å¥
        for line in st.session_state['all_segments'][:10]: 
            text_only = re.sub(r'^\d+[\.ã€\s]+', '', line)
            count = len(text_only)
            if count > 40: st.error(f"âŒ {line} ({count}å­—)")
            elif count < 20: st.warning(f"ğŸŸ¡ {line} ({count}å­—)")
            else: st.success(f"âœ… {line} ({count}å­—)")
    
    with col_b:
        edited_text = st.text_area("âœï¸ åˆ†é•œç¼–è¾‘åŒºï¼ˆå¯æ‰‹åŠ¨å¾®è°ƒï¼‰", "\n".join(st.session_state['all_segments']), height=300)
        st.session_state['all_segments'] = [l.strip() for l in edited_text.split('\n') if re.match(r'^\d+', l.strip())]

    st.markdown("---")

    # --- ç¬¬äºŒé˜¶æ®µï¼šåˆ†é•œæè¿° (ä¿æŒæ–‡æ¡ˆå¯¹ç…§) ---
    st.header("ç¬¬äºŒæ­¥ï¼šåˆ†é•œè§†è§‰æè¿°ï¼ˆå›¾æ–‡å¯¹ç…§ç‰ˆï¼‰")
    
    c1, c2 = st.columns([1, 1])
    with c1:
        char_desc = st.text_area("ğŸ‘¤ æ ¸å¿ƒè§’è‰²åŠç€è£…è®¾å®š (å¿…å¡«)", 
                                 placeholder="è§’è‰²åï¼š(å¤–è§‚ã€è¡£æœã€å‘å‹ç»†èŠ‚æå†™)",
                                 height=200)
    with c2:
        total = len(st.session_state['all_segments'])
        batch_size = 20
        batch_options = [f"ç¬¬ {i+1} - {min(i+batch_size, total)} ç»„" for i in range(0, total, batch_size)]
        selected_batch = st.selectbox("é€‰æ‹©å¤„ç†æ‰¹æ¬¡ (æ¯20ç»„ä¸€æ¨)", batch_options)
        
        # ç´¢å¼•è®¡ç®—
        nums = re.findall(r'\d+', selected_batch)
        start_idx, end_idx = int(nums[0]) - 1, int(nums[1])

    if st.button(f"ğŸ¨ ç”Ÿæˆ {selected_batch} çš„å›¾æ–‡å¯¹ç…§æè¿°", use_container_width=True):
        if not char_desc:
            st.error("è¯·å¡«å†™è§’è‰²è®¾å®šï¼")
        else:
            client = OpenAI(api_key=api_key, base_url=base_url)
            current_batch_txt = "\n".join(st.session_state['all_segments'][start_idx:end_idx])
            
            STEP2_PROMPT = f"""ä½ æ˜¯ä¸€ä¸ªè§†è§‰ç¾æœ¯å¯¼æ¼”ã€‚ä¸ºåˆ†é•œè„šæœ¬é…ä¸Šè§†è§‰æŒ‡ä»¤ã€‚

### æ ¸å¿ƒè§„åˆ™ï¼š
1. **å¯¹ç…§å¤è¯»**ï¼šå¿…é¡»ä»¥ã€åºå·. æ–‡æ¡ˆåŸæ–‡ã€‘å¼€å¤´ï¼Œä¸¥ç¦é—æ¼æ–‡æ¡ˆã€‚
2. **å½¢è±¡æ³¨å…¥**ï¼šæ–‡æ¡ˆä¸­å‡ºç°è§’è‰²åï¼Œå¿…é¡»å®Œæ•´å¤è¿°ä»¥ä¸‹å½¢è±¡å¹¶ç”¨æ‹¬å·åŒ…è£¹ã€‚
è§’è‰²è®¾å®šï¼š{char_desc}
3. **åœºæ™¯é”å®š**ï¼šæ¯ä¸ªåˆ†é•œå¿…é¡»æè¿°å…·ä½“åœ°ç‚¹å’Œç¯å¢ƒç»†èŠ‚ï¼Œé˜²æ­¢å‰²è£‚ã€‚
4. **æ ¼å¼è§„èŒƒ**ï¼š
   - ç”»é¢æè¿°ï¼š[ç¯å¢ƒæå†™], [å…‰å½±], (äººç‰©å…·ä½“å½¢è±¡æè¿°), [è§†è§’] {mj_suffix}
   - è§†é¢‘ç”Ÿæˆï¼š[åŠ¨ä½œè¿‡ç¨‹], [ç¥æ€å˜åŒ–], [é•œå¤´è¿åŠ¨]ã€‚
"""
            with st.spinner(f"æ­£åœ¨ç”Ÿæˆ {selected_batch} ..."):
                try:
                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[{"role": "system", "content": STEP2_PROMPT},
                                  {"role": "user", "content": current_batch_txt}],
                        temperature=0.4
                    )
                    st.session_state['batch_result'] = response.choices[0].message.content
                except Exception as e:
                    st.error(f"å¤„ç†å¤±è´¥: {str(e)}")

    if st.session_state['batch_result']:
        st.subheader(f"ğŸ¥ {selected_batch} è§†è§‰åˆ¶ä½œå…¨æ¡ˆ")
        st.text_area("æç¤ºè¯ç»“æœ", st.session_state['batch_result'], height=500)
        st.download_button(f"ğŸ“¥ ä¸‹è½½è¯¥æ‰¹æ¬¡", st.session_state['batch_result'], file_name=f"åˆ†é•œæè¿°_{selected_batch}.txt")

st.markdown("---")
st.caption("v6.7 | å›å½’é»„é‡‘å¹³è¡¡åˆ‡åˆ†é€»è¾‘ | ä¿æŒå›¾æ–‡å¯¹ç…§è¾“å‡º")
