import streamlit as st
import requests
import json

# é¡µé¢é…ç½®
st.set_page_config(page_title="æ¼«å‰§è‡ªåŠ¨åŒ–åˆ†é•œåŠ©æ‰‹", layout="wide")

st.title("ğŸ¬ æ¼«å‰§å‰§æƒ…è‡ªåŠ¨åŒ–åˆ†é•œæ•´ç†å·¥å…·")
st.markdown("ä¸Šä¼ å‰§æƒ…æ–‡æœ¬ï¼Œåˆ©ç”¨å¤§æ¨¡å‹è‡ªåŠ¨å®Œæˆåˆ†é•œåˆ‡åˆ†ã€‚")

# --- ä¾§è¾¹æ ï¼šAPI é…ç½® ---
with st.sidebar:
    st.header("API è®¾ç½®")
    model_provider = st.selectbox("é€‰æ‹©æ¨¡å‹ä¾›åº”å•†", ["DeepSeek", "ChatGPT (OpenAI)", "Gemini", "Groq", "è±†åŒ… (ç«å±±å¼•æ“)"])
    api_key = st.text_input("è¾“å…¥ API Key", type="password")
    
    if model_provider == "DeepSeek":
        base_url = "https://api.deepseek.com/v1/chat/completions"
        model_name = "deepseek-chat"
    elif model_provider == "ChatGPT (OpenAI)":
        base_url = "https://api.openai.com/v1/chat/completions"
        model_name = "gpt-4o"
    elif model_provider == "Gemini":
        # Gemini é€šå¸¸æœ‰ä¸“é—¨çš„ SDKï¼Œæ­¤å¤„å±•ç¤ºé€šç”¨çš„ OpenAI å…¼å®¹æ ¼å¼
        base_url = "https://generativelanguage.googleapis.com/v1beta/openai/chat/completions"
        model_name = "gemini-1.5-pro"
    elif model_provider == "Groq":
        base_url = "https://api.groq.com/openai/v1/chat/completions"
        model_name = "llama-3.1-70b-versatile"
    elif model_provider == "è±†åŒ… (ç«å±±å¼•æ“)":
        base_url = "https://ark.cn-beijing.volces.com/api/v3/chat/completions"
        model_name = st.text_input("è¾“å…¥ Endpoint ID (è±†åŒ…éœ€è¦)", value="")

# --- ä¸»ç•Œé¢ï¼šæ–‡ä»¶å¤„ç† ---
uploaded_file = st.file_uploader("é€‰æ‹©æœ¬åœ°æ–‡æœ¬æ–‡ä»¶ (.txt)", type=["txt"])

if uploaded_file is not None:
    # è¯»å–æ–‡æœ¬å†…å®¹
    content = uploaded_file.read().decode("utf-8")
    
    with st.expander("æŸ¥çœ‹åŸå§‹æ–‡æœ¬"):
        st.text(content)

    if st.button("å¼€å§‹åˆ†é•œå¤„ç†"):
        if not api_key:
            st.error("è¯·å…ˆåœ¨å·¦ä¾§è¾“å…¥ API Keyï¼")
        else:
            with st.spinner("AI æ­£åœ¨æ·±åº¦åˆ†æå¹¶è¿›è¡Œåˆ†é•œåˆ‡åˆ†ï¼Œè¯·ç¨å..."):
                try:
                    # æ„é€ ç³»ç»Ÿ Prompt
                    system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ¼«å‰§åˆ†é•œå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·æä¾›çš„åŸå§‹æ–‡æœ¬æ‹†åˆ†æˆé€‚åˆæ¼«å‰§åˆ¶ä½œçš„çŸ­åˆ†é•œã€‚
                    æ ¸å¿ƒè§„åˆ™ï¼š
                    1. åˆ†é•œåŸåˆ™ï¼šæ¯å½“è§’è‰²è¯´è¯åˆ‡æ¢ã€åœºæ™¯å˜æ¢ã€æˆ–ç”»é¢ä¸­åŠ¨ä½œå‘ç”Ÿæ”¹å˜æ—¶ï¼Œå¿…é¡»å¦èµ·ä¸€ä¸ªåºå·ã€‚
                    2. é›¶é—æ¼ï¼šå¿…é¡»åŒ…å«åŸæ–‡çš„æ‰€æœ‰å†…å®¹ï¼Œä¸æ¼ä¸€ä¸ªå­—ã€‚
                    3. é›¶æ·»åŠ ï¼šä¸¥ç¦æ·»åŠ åŸæ–‡ä»¥å¤–çš„æè¿°è¯ã€‚
                    4. æ ¼å¼ï¼šæ•°å­—åºå·+ç‚¹ï¼ˆå¦‚ 1. 2. ï¼‰ã€‚
                    5. é¡ºåºï¼šä¸¥æ ¼ä¿æŒåŸè‘—é¡ºåºã€‚"""

                    headers = {
                        "Authorization": f"Bearer {api_key}",
                        "Content-Type": "application/json"
                    }
                    
                    payload = {
                        "model": model_name,
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": f"è¯·å¯¹ä»¥ä¸‹å†…å®¹è¿›è¡Œåˆ†é•œå¤„ç†ï¼š\n\n{content}"}
                        ],
                        "temperature": 0.1 # è®¾ç½®ä½éšæœºæ€§ï¼Œä¿è¯ä¸¥æ ¼éµå¾ªåŸæ–‡
                    }

                    response = requests.post(base_url, headers=headers, json=payload)
                    response.raise_for_status()
                    result = response.json()['choices'][0]['message']['content']

                    st.success("åˆ†é•œå¤„ç†å®Œæˆï¼")
                    st.text_area("åˆ†é•œç»“æœè¾“å‡º", value=result, height=600)
                    
                    # ä¸‹è½½æŒ‰é’®
                    st.download_button(
                        label="ä¸‹è½½åˆ†é•œæ–‡ä»¶",
                        data=result,
                        file_name="åˆ†é•œæ•´ç†_output.txt",
                        mime="text/plain"
                    )

                except Exception as e:
                    st.error(f"å¤„ç†å‡ºé”™: {str(e)}")
