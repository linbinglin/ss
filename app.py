import streamlit as st
import requests
import json
import time

# ==========================================
# æ ¸å¿ƒå‡½æ•°ï¼šAI è°ƒç”¨ä¸æ‰¹å¤„ç†é€»è¾‘
# ==========================================

def call_ai(provider, key, mid, base_url, prompt):
    key = key.strip()
    default_models = {
        "DeepSeek": "deepseek-chat",
        "ChatGPT": "gpt-4o",
        "Gemini": "gemini-1.5-pro",
        "Grok (xAI)": "grok-beta",
        "ç¬¬ä¸‰æ–¹ä¸­è½¬ (OpenAIæ ¼å¼)": "gpt-4o"
    }
    target_model = mid if mid else default_models.get(provider, "")

    if provider == "ç¬¬ä¸‰æ–¹ä¸­è½¬ (OpenAIæ ¼å¼)":
        url = base_url.rstrip('/')
        if not url.endswith('/chat/completions'): url += '/chat/completions'
    else:
        urls = {
            "DeepSeek": "https://api.deepseek.com/chat/completions",
            "ChatGPT": "https://api.openai.com/v1/chat/completions",
            "Gemini": "https://generativelanguage.googleapis.com/v1beta/openai/chat/completions",
            "Grok (xAI)": "https://api.x.ai/v1/chat/completions",
            "è±†åŒ… (ç«å±±å¼•æ“)": "https://ark.cn-beijing.volces.com/api/v3/chat/completions"
        }
        url = urls.get(provider)

    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {key}"}
    payload = {
        "model": target_model,
        "messages": [{"role": "system", "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±æ¼«å‰§å¯¼æ¼”ï¼Œä¸¥è°¨æ‰§è¡Œè§†è§‰è„šæœ¬åˆ†æ­¥ä»»åŠ¡ã€‚"}, {"role": "user", "content": prompt}],
        "temperature": 0.1
    }
    
    try:
        final_url = f"{url}?key={key}" if provider == "Gemini" and "key=" not in url else url
        response = requests.post(final_url, headers=headers, json=payload, timeout=200)
        if response.status_code != 200:
            return f"API ERROR: {response.text}"
        return response.json()['choices'][0]['message']['content']
    except Exception as e:
        return f"ERROR: {str(e)}"

# ==========================================
# Streamlit ç•Œé¢
# ==========================================

st.set_page_config(page_title="æ¼«å‰§å¤§å¸ˆ v2.5 - å…¨é‡æ‰¹å¤„ç†ç‰ˆ", layout="wide")

# åˆå§‹åŒ–æ•°æ®
if 'final_storyboard' not in st.session_state: st.session_state.final_storyboard = ""
if 'step1_list' not in st.session_state: st.session_state.step1_list = []

with st.sidebar:
    st.header("âš™ï¸ 1. å¼•æ“é…ç½®")
    provider = st.selectbox("API ä¾›åº”å•†", ["ç¬¬ä¸‰æ–¹ä¸­è½¬ (OpenAIæ ¼å¼)", "DeepSeek", "ChatGPT", "Gemini", "Grok (xAI)", "è±†åŒ… (ç«å±±å¼•æ“)"])
    custom_base = st.text_input("API Base URL", value="https://blog.tuiwen.xyz/v1") if provider == "ç¬¬ä¸‰æ–¹ä¸­è½¬ (OpenAIæ ¼å¼)" else ""
    api_key = st.text_input("API Key", type="password")
    model_id = st.text_input("Model ID", value="gpt-4o")
    
    batch_size = st.slider("æ¯æ‰¹æ¬¡å¤„ç†åˆ†é•œæ•°", 5, 20, 10, help="å¦‚æœæ¨¡å‹ç»å¸¸æ–­å¼€ï¼Œè¯·è°ƒå°æ­¤æ•°å€¼")

    st.divider()
    st.header("ğŸ‘¤ 2. æ ¸å¿ƒè§’è‰²åº“")
    char_setup = st.text_area("äººç‰©è®¾å®š (å§“åï¼š(æè¿°))", height=300, 
                               placeholder="å®‰å¦™è¡£ï¼š(æè¿°...)\nèµµå°˜ï¼š(æè¿°...)")

st.title("ğŸ¬ æ¼«å‰§å…¨é‡è‡ªåŠ¨åŒ–åˆ†é•œå·¥ä½œç«™ v2.5")

tab1, tab2 = st.tabs(["ç¬¬ä¸€æ­¥ï¼šé€»è¾‘åˆ†é•œåˆå¹¶ä¸åˆ‡åˆ†", "ç¬¬äºŒæ­¥ï¼šè§†è§‰è„šæœ¬æ‰¹å¤„ç†ç”Ÿæˆ"])

# --- Tab 1: é€»è¾‘åˆ‡åˆ† ---
with tab1:
    st.subheader("ğŸ–‹ï¸ å‰§æœ¬é€»è¾‘å¤„ç†")
    st.markdown("å°†é›¶æ•£æ–‡æ¡ˆåˆå¹¶ä¸ºä¸€ä¸ªä¸ªã€è§†è§‰åˆ†é•œã€‘ã€‚è¦æ±‚ï¼šé€»è¾‘è¿è´¯ã€ä¸è¶…35å­—ã€‚")
    raw_script = st.text_area("è¾“å…¥åŸå§‹å‰§æœ¬", height=300)
    
    if st.button("å¼€å§‹é€»è¾‘åˆ‡åˆ†"):
        prompt_split = f"""
        ä»»åŠ¡ï¼šè¯·å¯¹ä»¥ä¸‹å‰§æœ¬è¿›è¡Œã€è§†è§‰åˆ†é•œé€»è¾‘åˆå¹¶ã€‘ã€‚
        
        è§„åˆ™ï¼š
        1. é€»è¾‘åˆå¹¶ï¼šä¸è¦æœºæ¢°åœ°ä¸€å¥è¯ä¸€åˆ†é•œã€‚å°†å‘ç”Ÿåœ¨ã€åŒä¸€åœºæ™¯ã€åŒä¸€åŠ¨ä½œåºåˆ—ã€‘ä¸‹çš„çŸ­å¥åˆå¹¶ä¸ºä¸€æ¡åˆ†é•œæ–‡æ¡ˆã€‚
        2. æ—¶é•¿é™åˆ¶ï¼šåˆå¹¶åçš„å•æ¡åˆ†é•œæ–‡æ¡ˆä¸¥ç¦è¶…è¿‡ 35 ä¸ªå­—ï¼ˆä¸ºäº†åŒ¹é…5ç§’è§†é¢‘ï¼‰ã€‚
        3. åŠ¨ä½œåˆ‡æ¢ï¼šå¦‚æœæ–‡æ¡ˆä¸­å‘ç”Ÿäº†æ˜æ˜¾çš„åŠ¨ä½œè½¬æŠ˜ï¼ˆå¦‚ä»â€œåç€â€å˜æˆâ€œç«™èµ·æ¥â€ï¼‰ï¼Œå³ä½¿å­—æ•°å¾ˆå°‘ä¹Ÿè¦æ‹†åˆ†ã€‚
        4. é›¶é—æ¼ï¼šåŒ…å«åŸæ–‡æ‰€æœ‰å­—ï¼Œä¸¥ç¦ä¿®æ”¹ã€‚
        5. æ ¼å¼ï¼šä»…è¾“å‡º åºå·. [æ–‡æ¡ˆå†…å®¹]
        
        å¾…å¤„ç†åŸæ–‡ï¼š
        {raw_script}
        """
        with st.spinner("æ­£åœ¨ä¼˜åŒ–åˆ†é•œé€»è¾‘..."):
            result = call_ai(provider, api_key, model_id, custom_base, prompt_split)
            # è§£ææˆåˆ—è¡¨æ–¹ä¾¿åç»­æ‰¹å¤„ç†
            st.session_state.step1_list = [line.strip() for line in result.split('\n') if line.strip()]
            st.success(f"é€»è¾‘åˆ‡åˆ†å®Œæˆï¼Œå…±è®¡ {len(st.session_state.step1_list)} é•œã€‚")
    
    st.write(st.session_state.step1_list)

# --- Tab 2: å…¨é‡æ‰¹å¤„ç† ---
with tab2:
    st.subheader("ğŸ–¼ï¸ è§†è§‰æŒ‡ä»¤å…¨é‡æ‰¹å¤„ç†ç”Ÿæˆ")
    st.warning("ç”±äºé•¿å‰§æœ¬å­—æ•°æå¤šï¼Œç³»ç»Ÿå°†è‡ªåŠ¨åˆ†æ‰¹æ¬¡è°ƒç”¨ AIã€‚è¯·å‹¿å…³é—­é¡µé¢ã€‚")
    
    if st.button("ğŸš€ å¼€å§‹å…¨é‡è‡ªåŠ¨ç”Ÿæˆ (æ”¯æŒ600+é•œ)"):
        if not st.session_state.step1_list or not char_setup:
            st.error("è¯·å…ˆå®Œæˆç¬¬ä¸€æ­¥ï¼Œå¹¶å¡«å…¥è§’è‰²è®¾å®šã€‚")
        else:
            total_list = st.session_state.step1_list
            st.session_state.final_storyboard = "" # é‡ç½®ç»“æœ
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # åˆ†æ‰¹æ¬¡å¾ªç¯
            for i in range(0, len(total_list), batch_size):
                chunk = total_list[i : i + batch_size]
                current_batch_str = "\n".join(chunk)
                
                status_text.text(f"æ­£åœ¨å¤„ç†ç¬¬ {i+1} è‡³ {min(i+batch_size, len(total_list))} é•œ...")
                
                prompt_visual = f"""
                ä½ æ˜¯ä¸€ä½æ¼«å‰§å¯¼æ¼”ã€‚è¯·ä¸ºä»¥ä¸‹åˆ†é•œç”Ÿæˆå¯¹åº”çš„ Midjourney ç”»é¢æè¿° å’Œ å³æ¢¦è§†é¢‘ç”ŸæˆæŒ‡ä»¤ã€‚
                
                ã€æ ¸å¿ƒäººç‰©è®¾å®šåº“ã€‘ï¼š
                {char_setup}
                
                ã€æœ¬æ¬¡å¾…å¤„ç†åˆ†é•œåˆ—è¡¨ã€‘ï¼š
                {current_batch_str}
                
                ã€ç”Ÿæˆè§„åˆ™ã€‘ï¼š
                1. ä¸¥æ ¼æ ¼å¼ï¼š
                   åºå·. [åŸæ–‡æ¡ˆå¯¹ç…§]
                   ç”»é¢æè¿°ï¼š[åœºæ™¯ã€æ™¯åˆ«ã€è§†è§’]ï¼Œè§’è‰²å(æè¿°è¯)ï¼Œè§’è‰²å(æè¿°è¯)... [é™æ€æ„å›¾ä¸å…‰å½±]
                   è§†é¢‘ç”Ÿæˆï¼š[åŠ¨æ€åŠ¨ä½œä¸è¡¨æƒ…å˜åŒ–]ï¼Œ[é•œå¤´è¿åŠ¨æè¿°]
                
                2. äººç‰©æè¿°æ³¨å…¥ï¼šå¿…é¡»åœ¨è§’è‰²ååç´§è·Ÿæ‹¬å·å†…çš„å®Œæ•´æè¿°è¯ï¼Œä¾‹å¦‚ï¼šå®‰å¦™è¡£(æ¸…ä¸½ç»ä¼¦çš„ç¾äºº...)ã€‚
                3. ä¸€è‡´æ€§ï¼šæ¯ä¸€é•œå¼€å¤´å¿…é¡»æè¿°åœºæ™¯èƒŒæ™¯ï¼ˆå¦‚ï¼šç ´æ—§æŸ´æˆ¿å†…ï¼‰ã€‚
                4. ä¸¥ç¦æ–­æ›´ï¼šå¿…é¡»å¤„ç†å®Œæˆ‘ç»™ä½ çš„ã€æ‰€æœ‰ã€‘åˆ†é•œï¼Œä¸å‡†åªå‡ºä¸€éƒ¨åˆ†ã€‚
                """
                
                chunk_result = call_ai(provider, api_key, model_id, custom_base, prompt_visual)
                
                st.session_state.final_storyboard += chunk_result + "\n\n"
                
                # æ›´æ–°è¿›åº¦
                progress = min((i + batch_size) / len(total_list), 1.0)
                progress_bar.progress(progress)
                
                # é¢„ç•™ 1 ç§’é˜²æ­¢è¯·æ±‚è¿‡å¿«è§¦å‘é™åˆ¶
                time.sleep(1)
            
            status_text.text("âœ… å…¨é‡ç”Ÿæˆå®Œæˆï¼")
            st.success("å…¨éƒ¨ 600+ åˆ†é•œå·²å¤„ç†å®Œæ¯•ã€‚")

    if st.session_state.final_storyboard:
        st.markdown(st.session_state.final_storyboard)
        st.download_button("ğŸ’¾ ä¸‹è½½å…¨é‡åˆ†é•œè„šæœ¬", st.session_state.final_storyboard, file_name="Full_Storyboard.txt")
