import streamlit as st
from openai import OpenAI
import re

# 1. é¡µé¢é…ç½®
st.set_page_config(page_title="AIåˆ†é•œå¯¼æ¼” v6.5", layout="wide", page_icon="ğŸ¬")

# æ•°æ®æŒä¹…åŒ–
if 'all_segments' not in st.session_state:
    st.session_state['all_segments'] = []
if 'batch_result' not in st.session_state:
    st.session_state['batch_result'] = ""

# 2. ä¾§è¾¹æ ï¼šå…¨å±€é…ç½®
st.sidebar.title("âš™ï¸ ç³»ç»Ÿé…ç½®")
api_key = st.sidebar.text_input("1. API Key", type="password")
base_url = st.sidebar.text_input("2. æ¥å£åœ°å€", value="https://blog.tuiwen.xyz/v1")

st.sidebar.markdown("---")
st.sidebar.subheader("3. Midjourney ç”»é£åç¼€")
mj_suffix = st.sidebar.text_input("åç¼€è¯ (ä»…åœ¨ç¬¬äºŒæ­¥ç”Ÿæ•ˆ)", value="--ar 16:9 --v 6.1 --style raw")

st.sidebar.markdown("---")
st.sidebar.subheader("4. æ¨¡å‹è®¾ç½®")
model_options = ["gpt-4o", "claude-3-5-sonnet-20240620", "deepseek-chat", "è‡ªå®šä¹‰æ¨¡å‹"]
selected_option = st.sidebar.selectbox("é€‰æ‹©æ¨¡å‹", model_options)
if selected_option == "è‡ªå®šä¹‰æ¨¡å‹":
    model_id = st.sidebar.text_input("æ‰‹åŠ¨è¾“å…¥ Model ID")
else:
    model_id = selected_option

st.title("ğŸ¬ ç”µå½±è§£è¯´å…¨æµç¨‹åˆ†é•œå·¥å…·")
st.caption("ç¬¬ä¸€æ­¥ï¼š100% è¿˜åŸ V5.1 ç‰©ç†åˆ‡åˆ†é€»è¾‘ | ç¬¬äºŒæ­¥ï¼šè§†è§‰é”šå®šä¸æ‰¹å¤„ç†")

# --- ç¬¬ä¸€é˜¶æ®µï¼šè¿˜åŸ V5.1 ç‰©ç†åˆ‡åˆ† ---
st.header("ç¬¬ä¸€æ­¥ï¼šé€»è¾‘åˆ†é•œï¼ˆè¿˜åŸ V5.1 çº¯å‡€éª¨æ¶ï¼‰")
st.info("ğŸ’¡ é€»è¾‘ï¼šæ­¤æ­¥éª¤æ‰§è¡Œâ€˜ç‰©ç†åˆ‡å‰²â€™ã€‚ç›®æ ‡ï¼šæ¯ä¸ªåˆ†é•œ 25-35 å­—ï¼ŒåŒ…å«ä¸€ä¸ªæ ¸å¿ƒè§†è§‰å•å…ƒã€‚")

uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼ æ–‡æ¡ˆ (TXT)", type=['txt'])

if uploaded_file:
    raw_text = uploaded_file.getvalue().decode("utf-8", errors="ignore")
    # V5.1 çµé­‚é€»è¾‘ï¼šå½»åº•ç²‰ç¢åŸæ–‡æ ¼å¼ï¼Œåˆå¹¶ä¸ºçº¯æ–‡å­—æµ
    clean_stream = "".join(raw_text.split())

    if st.button("ğŸš€ ç”Ÿæˆç‰©ç†åˆ†é•œè„šæœ¬", use_container_width=True):
        if not api_key or not model_id:
            st.error("è¯·é…ç½® API ä¿¡æ¯")
        else:
            client = OpenAI(api_key=api_key, base_url=base_url)
            
            # ã€æ ¸å¿ƒã€‘è¿™é‡Œå®Œå…¨å¤åŸ V5.1 çš„æç¤ºè¯ï¼Œä¸æ”¹åŠ¨ä»»ä½•å­—
            STEP1_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæå…¶ä¸¥è°¨çš„ç”µå½±åˆ†é•œå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†æä¾›çš„ã€çº¯æ–‡å­—æµã€‘æ‹†è§£ä¸ºã€æ•°å­—ç¼–å·çš„åˆ†é•œè„šæœ¬ã€‘ã€‚

### æ ¸å¿ƒè§„åˆ™ï¼š
1. **ä¸¥æ ¼ç¼–å·**ï¼šæ¯ä¸€ä¸ªåˆ†é•œå¿…é¡»ä»¥â€œ1.â€ â€œ2.â€ â€œ3.â€ è¿™ç§æ•°å­—åºå·å¼€å¤´ï¼Œä¸å¾—é—æ¼ã€‚
2. **æ‹’ç»æ³¨é‡Š**ï¼šä¸¥ç¦åœ¨åˆ†é•œä¸­æ·»åŠ ä»»ä½•æ‹¬å·ã€åˆ†æã€é•œå¤´æ„å›¾æˆ–é¢å¤–æè¿°ã€‚åªéœ€è¾“å‡ºâ€œæ•°å­—. åŸæ–‡â€ã€‚
3. **è§†è§‰å•å…ƒåˆ‡åˆ†ï¼ˆä¸¥ç¦åˆå¹¶ï¼‰**ï¼š
   - ä¸€ä¸ªåˆ†é•œåªèƒ½åŒ…å«ä¸€ä¸ªè§†è§‰é‡ç‚¹æˆ–æ ¸å¿ƒåŠ¨ä½œã€‚
   - ä¸¥ç¦ä¸ºäº†çœäº‹å°†ä¸¤ä¸ªä¸åŒçš„åŠ¨ä½œåˆå¹¶åœ¨ä¸€ä¸ªåˆ†é•œé‡Œã€‚
4. **å­—æ•°ä¸æ—¶é•¿å¯¹é½**ï¼š
   - æ¯ä¸ªåˆ†é•œç›®æ ‡å­—æ•°ä¸º 25-35 å­—ã€‚
   - ç»å¯¹ä¸¥ç¦è¶…è¿‡ 40 å­—ã€‚
5. **åŸæ–‡é›¶æ”¹åŠ¨**ï¼šä¸å‡†æ”¹å­—ã€åˆ å­—ã€åŠ å­—ã€‚
"""
            with st.spinner("æ­£åœ¨ä»¥ V5.1 æœºæ¢°é€»è¾‘åˆ‡åˆ†åˆ†é•œ..."):
                try:
                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[{"role": "system", "content": STEP1_PROMPT},
                                  {"role": "user", "content": f"è¯·å¯¹ä»¥ä¸‹æ–‡å­—æµè¿›è¡Œç­‰æƒé‡çš„ç²¾ç¡®åˆ†é•œï¼Œå¿…é¡»å¸¦æ•°å­—ç¼–å·ï¼š\n\n{clean_stream}"}],
                        temperature=0.1
                    )
                    st.session_state['all_segments'] = [l.strip() for l in response.choices[0].message.content.split('\n') if re.match(r'^\d+', l.strip())]
                except Exception as e:
                    st.error(f"å¤„ç†å¤±è´¥: {str(e)}")

# ç¬¬ä¸€æ­¥ç»“æœé¢„è§ˆä¸ç»Ÿè®¡
if st.session_state['all_segments']:
    st.subheader(f"ğŸ“‹ åˆ†é•œéª¨æ¶é¢„è§ˆ (å…± {len(st.session_state['all_segments'])} ç»„)")
    
    col_a, col_b = st.columns([1, 2])
    with col_a:
        for line in st.session_state['all_segments'][:15]: # é¢„è§ˆå‰15æ¡
            text_only = re.sub(r'^\d+[\.ã€\s]+', '', line)
            count = len(text_only)
            if count > 40: st.error(f"âŒ {line} ({count}å­—)")
            else: st.success(f"âœ… {line} ({count}å­—)")
    
    with col_b:
        edited_text = st.text_area("âœï¸ ç‰©ç†åˆ†é•œç¼–è¾‘åŒº", "\n".join(st.session_state['all_segments']), height=400)
        st.session_state['all_segments'] = [l.strip() for l in edited_text.split('\n') if re.match(r'^\d+', l.strip())]

    st.markdown("---")

    # --- ç¬¬äºŒé˜¶æ®µï¼šåˆ†é•œæè¿° (ç”¨æˆ·å¾®è°ƒç‰ˆ) ---
    st.header("ç¬¬äºŒæ­¥ï¼šåˆ†é•œè§†è§‰æè¿°ï¼ˆåˆ†æ‰¹æ‰§è¡Œï¼‰")
    
    c1, c2 = st.columns([1, 1])
    with c1:
        char_desc = st.text_area("ğŸ‘¤ è§’è‰²å½¢è±¡åŠç€è£…è®¾å®š", 
                                 placeholder="è§’è‰²Aï¼š(å½¢è±¡æå†™)\nè§’è‰²Bï¼š(å½¢è±¡æå†™)",
                                 height=200)
    with c2:
        total = len(st.session_state['all_segments'])
        batch_size = 20
        batch_options = [f"ç¬¬ {i+1} - {min(i+batch_size, total)} ç»„" for i in range(0, total, batch_size)]
        selected_batch = st.selectbox("é€‰æ‹©å½“å‰è¦ç”Ÿæˆçš„æ‰¹æ¬¡ (æ¯æ¬¡20ç»„)", batch_options)
        
        # ç´¢å¼•æå–
        nums = re.findall(r'\d+', selected_batch)
        start_idx, end_idx = int(nums[0]) - 1, int(nums[1])

    if st.button(f"ğŸ¨ ä¸º {selected_batch} ç”Ÿæˆè§†è§‰æè¿°è¯", use_container_width=True):
        if not char_desc:
            st.error("è¯·å¡«å†™è§’è‰²è®¾å®šï¼")
        else:
            client = OpenAI(api_key=api_key, base_url=base_url)
            current_batch_txt = "\n".join(st.session_state['all_segments'][start_idx:end_idx])
            
            # ç¬¬äºŒæ­¥æç¤ºè¯ï¼šå¢åŠ è§’è‰²æ‹¬å·è°ƒç”¨ã€åœºæ™¯é”å®šã€åç¼€æ·»åŠ 
            STEP2_PROMPT = f"""ä½ æ˜¯ä¸€ä¸ªè§†è§‰ç¾æœ¯å¯¼æ¼”ã€‚ä¸ºåˆ†é•œè„šæœ¬é…ä¸Šè§†è§‰æŒ‡ä»¤ã€‚

### æ ¸å¿ƒè§„åˆ™ï¼š
1. **è§†è§‰é”šå®š**ï¼šå½“æ–‡æ¡ˆä¸­å‡ºç°è§’è‰²æ—¶ï¼Œå¿…é¡»å®Œæ•´è°ƒç”¨ä»¥ä¸‹å½¢è±¡ï¼Œå¹¶ä½¿ç”¨æ‹¬å·åŒ…è£¹ã€‚
è§’è‰²åˆ—è¡¨ï¼š{char_desc}
2. **åœºæ™¯é”å®š**ï¼šæ¯ä¸ªåˆ†é•œå¿…é¡»æè¿°åœºæ™¯åœ°ç‚¹å’Œç¯å¢ƒæ°›å›´ï¼Œä¸¥ç¦éšæœºç”Ÿæˆã€‚
3. **æ ¼å¼åŒ–è¾“å‡º**ï¼š
   - ç”»é¢æè¿°ï¼š[åœºæ™¯ä½ç½®], [å…‰å½±ç»†èŠ‚], (äººç‰©å®Œæ•´å½¢è±¡æå†™), [è§†è§’æ„å›¾] {mj_suffix}
   - è§†é¢‘ç”Ÿæˆï¼š[äººç‰©å…·ä½“åŠ¨ä½œ], [ç¥æ€æ¼”å˜], [é•œå¤´è¿åŠ¨]ã€‚ç¡®ä¿5ç§’å†…å®Œæˆã€‚
4. **åŸæ–‡å¤è¯»**ï¼šä¸¥ç¦æ”¹åŠ¨åˆ†é•œä¸­çš„æ–‡æ¡ˆåŸæ–‡ã€‚
"""
            with st.spinner(f"æ­£åœ¨åˆ†æ {selected_batch} çš„ç”»é¢..."):
                try:
                    response = client.chat.completions.create(
                        model=model_id,
                        messages=[{"role": "system", "content": STEP2_PROMPT},
                                  {"role": "user", "content": current_batch_txt}],
                        temperature=0.4
                    )
                    st.session_state['batch_result'] = response.choices[0].message.content
                except Exception as e:
                    st.error(f"å¤„ç†å¤±è´¥: {str(e)}")

    if st.session_state['batch_result']:
        st.subheader(f"ğŸ¥ {selected_batch} è§†è§‰æ–¹æ¡ˆç»“æœ")
        st.text_area("æç¤ºè¯é¢„è§ˆ", st.session_state['batch_result'], height=400)
        st.download_button(f"ğŸ“¥ ä¸‹è½½ {selected_batch}", st.session_state['batch_result'], file_name=f"åˆ†é•œæè¿°_{selected_batch}.txt")

st.markdown("---")
st.caption("v6.5 å®Œç¾å›å½’ç‰ˆ | é”å®š V5.1 åˆ†é•œé€»è¾‘ | æ”¯æŒæ‰¹å¤„ç†ä¸ç”»é£åç¼€è¯")
