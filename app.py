import streamlit as st
import requests
import json
import re

# ==========================================
# æ ¸å¿ƒå‡½æ•°ï¼šç”µå½±å¯¼æ¼”æ€ç»´åˆ†é•œä¸è§†è§‰ç”Ÿæˆ
# ==========================================

def call_ai(provider, key, mid, base_url, prompt):
    key = key.strip()
    default_models = {
        "DeepSeek": "deepseek-chat",
        "ChatGPT": "gpt-4o",
        "Gemini": "gemini-1.5-pro",
        "Grok (xAI)": "grok-beta",
        "ç¬¬ä¸‰æ–¹ä¸­è½¬ (OpenAIæ ¼å¼)": "gpt-4o"
    }
    target_model = mid if mid else default_models.get(provider, "")

    if provider == "ç¬¬ä¸‰æ–¹ä¸­è½¬ (OpenAIæ ¼å¼)":
        url = base_url.rstrip('/')
        if not url.endswith('/chat/completions'): url += '/chat/completions'
    else:
        urls = {
            "DeepSeek": "https://api.deepseek.com/chat/completions",
            "ChatGPT": "https://api.openai.com/v1/chat/completions",
            "Gemini": "https://generativelanguage.googleapis.com/v1beta/openai/chat/completions",
            "Grok (xAI)": "https://api.x.ai/v1/chat/completions",
            "è±†åŒ… (ç«å±±å¼•æ“)": "https://ark.cn-beijing.volces.com/api/v3/chat/completions"
        }
        url = urls.get(provider)

    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {key}"}
    payload = {
        "model": target_model,
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æ‹¥æœ‰é¡¶çº§å¯¼æ¼”æ€ç»´çš„æ¼«å‰§åˆ†é•œå¸ˆã€‚ä½ æ“…é•¿é€å­—ç†è§£æ–‡æ¡ˆé€»è¾‘ï¼Œå¹¶å°†æ–‡æ¡ˆè½¬åŒ–ä¸ºæå…·æ•…äº‹æ„Ÿã€ç”µå½±æ„Ÿçš„ç”»é¢è„šæœ¬ã€‚"},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.3 # ç¨å¾®æé«˜ä¸€ç‚¹åˆ›é€ åŠ›ä»¥å¢å¼ºæ•…äº‹æ„Ÿï¼Œä½†ä¿æŒæ ¼å¼ç¨³å®š
    }
    
    try:
        final_url = f"{url}?key={key}" if provider == "Gemini" and "key=" not in url else url
        response = requests.post(final_url, headers=headers, json=payload, timeout=240)
        if response.status_code != 200:
            return f"API å‡ºé”™: {response.text}"
        return response.json()['choices'][0]['message']['content']
    except Exception as e:
        return f"ç³»ç»Ÿè¿æ¥å¼‚å¸¸: {str(e)}"

# ==========================================
# ç•Œé¢å¸ƒå±€ä¸çŠ¶æ€ç®¡ç†
# ==========================================

st.set_page_config(page_title="æ¼«å‰§å¯¼æ¼”å·¥ä½œç«™ v2.8", layout="wide")

# åˆå§‹åŒ– Session çŠ¶æ€ï¼Œé˜²æ­¢åˆ·æ–°ä¸¢å¤±æ•°æ®
if 'step1_list' not in st.session_state: st.session_state.step1_list = []
if 'current_index' not in st.session_state: st.session_state.current_index = 0
if 'accumulated_storyboard' not in st.session_state: st.session_state.accumulated_storyboard = ""

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("âš™ï¸ å¼•æ“é…ç½®")
    provider = st.selectbox("API ä¾›åº”å•†", ["ç¬¬ä¸‰æ–¹ä¸­è½¬ (OpenAIæ ¼å¼)", "DeepSeek", "ChatGPT", "Gemini", "Grok (xAI)", "è±†åŒ… (ç«å±±å¼•æ“)"])
    custom_base = st.text_input("API Base URL", value="https://blog.tuiwen.xyz/v1") if provider == "ç¬¬ä¸‰æ–¹ä¸­è½¬ (OpenAIæ ¼å¼)" else ""
    api_key = st.text_input("API Key", type="password")
    model_id = st.text_input("Model ID", value="gpt-4o")
    
    st.divider()
    st.header("ğŸ‘¤ æ ¸å¿ƒè§’è‰²æè¿°åº“")
    char_setup = st.text_area("äººç‰©è®¾å®š (æ ¼å¼ï¼šå§“åï¼š(æè¿°è¯))", height=350, placeholder="å®‰å¦™è¡£ï¼š(æ¸…ä¸½ç»ä¼¦...)\nèµµå°˜ï¼š(æ·±é‚ƒå†·å³»...)")
    
    if st.button("ğŸ”´ é‡ç½®æ‰€æœ‰æµç¨‹"):
        st.session_state.current_index = 0
        st.session_state.accumulated_storyboard = ""
        st.session_state.step1_list = []
        st.rerun()

# --- ä¸»ç•Œé¢ ---
st.title("ğŸ¬ æ¼«å‰§å…¨æµç¨‹åˆ†é•œç«™ - å¯¼æ¼”æ€ç»´ç‰ˆ")

tab1, tab2 = st.tabs(["ç¬¬ä¸€æ­¥ï¼šç”µå½±å¯¼æ¼”åˆ†é•œåˆ‡åˆ†", "ç¬¬äºŒæ­¥ï¼šè§†è§‰æè¿°æŒ‡ä»¤ç”Ÿæˆ"])

# --- ç¬¬ä¸€æ­¥ï¼šé€»è¾‘åˆ‡åˆ†é€»è¾‘ ---
with tab1:
    st.subheader("ğŸ–‹ï¸ å‰§æœ¬é€»è¾‘æ·±åº¦æ‹†è§£")
    raw_script = st.text_area("åœ¨æ­¤è¾“å…¥å‰§æœ¬åŸæ–‡", height=300)
    
    if st.button("æ‰§è¡Œå¯¼æ¼”åˆ†é•œ"):
        if not api_key: st.error("è¯·å…ˆå¡«å…¥ API Key")
        else:
            prompt_split = f"""
            ä½ æ˜¯ä¸€ä¸ªä¼˜ç§€çš„ç”µå½±è§£è¯´å¯¼æ¼”ï¼Œè¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œåˆ†é•œã€‚
            
            ã€å¯¼æ¼”ä»»åŠ¡ã€‘ï¼š
            1. é€å­—é€å¥ç†è§£æ–‡æœ¬ä¸­çš„å†…å®¹ï¼Œç„¶åå¯¹æ–‡æœ¬è¿›è¡Œåˆ†æ®µå¤„ç†ã€‚
            2. é€»è¾‘åŸåˆ™ï¼šæ¯ä¸ªè§’è‰²å¯¹è¯åˆ‡æ¢ã€åœºæ™¯åˆ‡æ¢ã€åŠ¨ä½œç”»é¢æ”¹å˜ï¼Œéƒ½éœ€è¦è®¾å®šä¸ºä¸‹ä¸€ä¸ªåˆ†é•œã€‚
            3. ç¦æ­¢ä¿®æ”¹åŸæ–‡ï¼šä¸å¯é—æ¼ã€æ”¹å˜åŸæ–‡æ•…äº‹ç»“æ„ï¼Œä¸¥ç¦æ·»åŠ åŸæ–‡ä»¥å¤–å†…å®¹ã€‚
            4. è¿è´¯æµç•…ï¼šä¸è¦ä¸€å¥è¯ä¸€ä¸ªåˆ†é•œï¼Œè€Œæ˜¯æ ¹æ®å‰§æƒ…æ¥åˆ’åˆ†ï¼Œè®©åˆ†é•œè¿è´¯æµç•…ã€‚
            5. æ—¶é•¿æ§åˆ¶ï¼šç”±äºæ–‡æ¡ˆè¦é…éŸ³ï¼Œå•é•œå¤´é™åˆ¶åœ¨5ç§’å†…ï¼ˆçº¦35ä¸ªæ±‰å­—ï¼‰ã€‚å¦‚æœå‰§æƒ…è¿è´¯ä½†å­—æ•°è¶…è¿‡35å­—ï¼Œå¿…é¡»åœ¨é€»è¾‘è½¬æŠ˜ç‚¹åˆ‡åˆ†ã€‚
            
            ã€æ ¼å¼è¦æ±‚ã€‘ï¼š
            ä»…è¾“å‡ºåºå·åˆ—è¡¨ï¼Œæ ¼å¼ä¸ºï¼šåºå·. [æ–‡æ¡ˆå†…å®¹]
            
            å¾…å¤„ç†æ–‡æ¡ˆï¼š
            {raw_script}
            """
            with st.spinner("å¯¼æ¼”æ­£åœ¨é€å¥ç ”è¯»å‰§æœ¬å¹¶åˆ’åˆ†åˆ†é•œ..."):
                result = call_ai(provider, api_key, model_id, custom_base, prompt_split)
                
                # å¢å¼ºçš„æ­£åˆ™è¡¨è¾¾å¼æå–é€»è¾‘
                lines = result.split('\n')
                st.session_state.step1_list = [l.strip() for l in lines if re.match(r"^\d+[\.ï¼ã€\s]", l.strip())]
                
                if not st.session_state.step1_list:
                    st.error("æœªèƒ½è¯†åˆ«åˆ†é•œï¼Œè¯·æ£€æŸ¥ AI è¿”å›ç»“æœã€‚")
                    st.code(result)
                else:
                    st.success(f"åˆ†é•œåˆ’åˆ†æˆåŠŸï¼å…±è®¡ {len(st.session_state.step1_list)} ç»„ã€‚")
                    st.session_state.current_index = 0

    if st.session_state.step1_list:
        st.text_area("åˆ†é•œé¢„è§ˆ (å¯æ‰‹åŠ¨ä¿®æ”¹æ–‡æ¡ˆ)", value="\n".join(st.session_state.step1_list), height=300)

# --- ç¬¬äºŒæ­¥ï¼šè§†è§‰ç”Ÿæˆé€»è¾‘ ---
with tab2:
    st.subheader("ğŸ–¼ï¸ ç”»é¢æè¿°ä¸è§†é¢‘ç”Ÿæˆ (é€é•œæ³¨å…¥)")
    
    if not st.session_state.step1_list:
        st.info("è¯·å…ˆå®Œæˆç¬¬ä¸€æ­¥åˆ†é•œæ‹†åˆ†ã€‚")
    else:
        curr = st.session_state.current_index
        total = len(st.session_state.step1_list)
        st.progress(curr / total)
        st.write(f"ğŸ“Š è¿›åº¦ï¼š{curr} / {total}")

        col1, col2 = st.columns(2)
        with col1:
            batch_size = st.number_input("æ¯æ¬¡ç”Ÿæˆåˆ†é•œæ•°", 1, 50, 20)
        
        if curr < total:
            if st.button(f"ğŸš€ ç”Ÿæˆä¸‹ {batch_size} ç»„è§†è§‰è„šæœ¬"):
                end = min(curr + batch_size, total)
                target_data = "\n".join(st.session_state.step1_list[curr:end])
                
                prompt_visual = f"""
                ä½ æ˜¯ä¸€ä½æ¼«å‰§è§†è§‰å¯¼æ¼”ã€‚è¯·ä¸ºä»¥ä¸‹åˆ†é•œç”Ÿæˆå¯¹åº”çš„ Midjourney ç”»é¢æè¿° å’Œ å³æ¢¦è§†é¢‘ç”ŸæˆæŒ‡ä»¤ã€‚
                
                ã€æ ¸å¿ƒäººç‰©è®¾å®šã€‘ï¼š
                {char_setup}
                
                ã€å¾…å¤„ç†åˆ†é•œã€‘ï¼š
                {target_data}
                
                ã€ç”Ÿæˆè§„åˆ™ (ä¸¥æ ¼æ‰§è¡Œ)ã€‘ï¼š
                1. æ¯ä¸€ä¸ªåˆ†é•œå¿…é¡»åŒ…å«ä¸”ä»…åŒ…å«ä»¥ä¸‹ä¸‰éƒ¨åˆ†ï¼š
                   åºå·. [åŸæ–‡æ¡ˆå¯¹ç…§]
                   ç”»é¢æè¿°ï¼šæè¿°æ‰€åœ¨åœºæ™¯ã€æ™¯åˆ«(ç‰¹å†™/å…¨æ™¯)ã€è§†è§’ã€‚å¦‚æœå‡ºç°äººç‰©ï¼Œå¿…é¡»ä½¿ç”¨(å§“å+å®Œæ•´è®¾å®š)çš„å½¢å¼ï¼Œä¾‹å¦‚ï¼š(å®‰å¦™è¡£ï¼Œæ¸…ä¸½ç»ä¼¦çš„ç¾äºº...)ã€‚
                   è§†é¢‘ç”Ÿæˆï¼šæ ¹æ®æ–‡æ¡ˆæè¿°ç”»é¢ä¸­è§’è‰²çš„åŠ¨æ€åŠ¨ä½œã€ç¥æ€å˜åŒ–ã€é•œå¤´è¯­è¨€ã€‚
                2. äººç‰©æè¿°ï¼šå¿…é¡»ç”¨æ‹¬å·()æ‰©ä¸Šè§’è‰²è®¾å®šè¯ã€‚å½“åˆ†é•œå‡ºç°å¤šä¸ªè§’è‰²æ—¶ï¼Œæ¯ä¸ªè§’è‰²éƒ½è¦ç‹¬ç«‹å¸¦æ‹¬å·æè¿°ã€‚
                3. ä¸€è‡´æ€§ï¼šæ¯ä¸ªåˆ†é•œå¿…é¡»æè¿°æ‰€åœ¨åœºæ™¯ï¼Œç¡®ä¿è§†è§‰è¿è´¯ã€‚
                
                ã€æ¡ˆä¾‹å‚è€ƒã€‘ï¼š
                1. [æˆ‘æ‹‰è¿‡çµæ›¦çš„æ‰‹ è½¬èº«ç¦»å¼€]
                ç”»é¢æè¿°ï¼šäº¬åŸè¡—è§’ï¼Œ(èµµæ¸…æœˆï¼Œæ¸…å†·ç¾äººï¼Œçœ‰çœ¼æç²¾è‡´...)æ‹‰ç€(èµµçµæ›¦ï¼Œæ˜è‰³å¼ æ‰¬ï¼Œæçœ¼æ¡ƒè…®...)çš„æ‰‹ã€‚
                è§†é¢‘ç”Ÿæˆï¼šç™½è¡£å¥³äººç‰µç€é»„è¡£å¥³äººçš„æ‰‹è½¬å‘ä¸€è¾¹ï¼Œé•œå¤´è·Ÿéšä¸¤äººç§»åŠ¨ï¼Œè·¯äººè™šåŒ–ã€‚
                """
                
                with st.spinner(f"æ­£åœ¨ç”Ÿæˆç¬¬ {curr+1} åˆ° {end} é•œ..."):
                    batch_res = call_ai(provider, api_key, model_id, custom_base, prompt_visual)
                    if "API å‡ºé”™" not in batch_res:
                        st.session_state.accumulated_storyboard += "\n\n" + batch_res
                        st.session_state.current_index = end
                        st.rerun() # å¼ºåˆ¶åˆ·æ–°ä»¥æ˜¾ç¤ºæœ€æ–°ç»“æœ
                    else:
                        st.error(batch_res)
        else:
            st.success("âœ… å…¨å‰§åˆ†é•œè§†è§‰æè¿°å·²å…¨éƒ¨å‡ºç‚‰ï¼")

        if st.session_state.accumulated_storyboard:
            st.divider()
            st.text_area("å…¨é‡è§†è§‰è„šæœ¬æ±‡æ€»", value=st.session_state.accumulated_storyboard, height=500)
            st.download_button("ğŸ’¾ ä¸‹è½½è„šæœ¬æ–‡ä»¶", st.session_state.accumulated_storyboard, file_name="Storyboard_Production.txt")
